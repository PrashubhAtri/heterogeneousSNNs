{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvolutionStrategy import ESModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The `ESModel` Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ESModel` can be used for any `torch` models, as long as it is a subclass of `nn.module`. Here we define a simple MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `ESModel`, we can directly pass the model class name, in this case `MLP`, to the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_model = ESModel(Model=MLP, param_std=0.01,Optimizer=torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `samples()` method returns an iterator, allowing us to iterate through models whose parameters were drawn from the normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "MLP(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for model in es_model.samples(sample_size=2):\n",
    "    print(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sampling, we need to obtain loss to estimate the gradient. This is done outside of the `ESModel` class. After doing so, the `gradient_descent(loss)` method takes a tensor with shape [nb_samples,], each entry corresponds to a loss for a sample. It then estimates the gradient of loss w.r.t. parameter $\\nabla_\\theta L$ and performs gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_loss = torch.randn([2,]).to(device) # since the sample size is 2\n",
    "es_model.gradient_descent(fake_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we iterate these two operations to train the model. The `get_best_model()` method returns a model with parameters being their estimated means. This can be used in validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = es_model.get_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example: Training CNN on MNIST Dataset using `ESModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.344096\n",
      "loss: 2.365517\n",
      "loss: 2.346449\n",
      "loss: 2.361961\n",
      "loss: 2.386756\n",
      "loss: 2.364064\n",
      "loss: 2.371230\n",
      "loss: 2.377149\n",
      "loss: 2.401134\n",
      "loss: 2.363524\n",
      "loss: 2.374210\n",
      "loss: 2.383887\n",
      "loss: 2.389943\n",
      "loss: 2.411423\n",
      "loss: 2.409988\n",
      "loss: 2.418119\n",
      "loss: 2.437249\n",
      "loss: 2.437269\n",
      "loss: 2.420153\n",
      "loss: 2.428493\n",
      "loss: 2.448111\n",
      "loss: 2.442569\n",
      "loss: 2.423686\n",
      "loss: 2.454573\n",
      "loss: 2.448188\n",
      "loss: 2.448636\n",
      "loss: 2.450336\n",
      "loss: 2.445827\n",
      "loss: 2.434328\n",
      "loss: 2.430256\n",
      "loss: 2.446907\n",
      "loss: 2.458442\n",
      "loss: 2.464206\n",
      "loss: 2.460428\n",
      "loss: 2.455112\n",
      "loss: 2.487108\n",
      "loss: 2.464961\n",
      "loss: 2.475064\n",
      "loss: 2.490706\n",
      "loss: 2.494599\n",
      "loss: 2.486852\n",
      "loss: 2.506617\n",
      "loss: 2.485558\n",
      "loss: 2.485729\n",
      "loss: 2.488230\n",
      "loss: 2.512548\n",
      "loss: 2.467071\n",
      "loss: 2.501066\n",
      "loss: 2.503813\n",
      "loss: 2.499095\n",
      "loss: 2.506607\n",
      "loss: 2.494600\n",
      "loss: 2.527209\n",
      "loss: 2.539393\n",
      "loss: 2.513906\n",
      "loss: 2.537012\n",
      "loss: 2.520734\n",
      "loss: 2.557217\n",
      "loss: 2.505289\n",
      "loss: 2.528536\n",
      "loss: 2.550517\n",
      "loss: 2.502917\n",
      "loss: 2.493002\n",
      "loss: 2.501419\n",
      "loss: 2.539133\n",
      "loss: 2.447045\n",
      "loss: 2.491967\n",
      "loss: 2.479625\n",
      "loss: 2.419677\n",
      "loss: 2.426086\n",
      "loss: 2.503362\n",
      "loss: 2.446651\n",
      "loss: 2.413969\n",
      "loss: 2.484536\n",
      "loss: 2.466382\n",
      "loss: 2.426744\n",
      "loss: 2.410627\n",
      "loss: 2.450605\n",
      "loss: 2.412691\n",
      "loss: 2.388695\n",
      "loss: 2.434709\n",
      "loss: 2.371585\n",
      "loss: 2.444685\n",
      "loss: 2.460561\n",
      "loss: 2.438470\n",
      "loss: 2.461855\n",
      "loss: 2.488819\n",
      "loss: 2.449932\n",
      "loss: 2.467139\n",
      "loss: 2.446504\n",
      "loss: 2.432240\n",
      "loss: 2.438568\n",
      "loss: 2.440495\n",
      "loss: 2.416246\n",
      "loss: 2.456388\n",
      "loss: 2.432551\n",
      "loss: 2.477173\n",
      "loss: 2.491344\n",
      "loss: 2.480829\n",
      "loss: 2.493844\n",
      "loss: 2.459792\n",
      "loss: 2.426244\n",
      "loss: 2.492481\n",
      "loss: 2.506153\n",
      "loss: 2.433221\n",
      "loss: 2.423185\n",
      "loss: 2.478845\n",
      "loss: 2.454991\n",
      "loss: 2.509263\n",
      "loss: 2.537498\n",
      "loss: 2.503913\n",
      "loss: 2.450319\n",
      "loss: 2.490007\n",
      "loss: 2.453379\n",
      "loss: 2.457387\n",
      "loss: 2.417061\n",
      "loss: 2.474176\n",
      "loss: 2.460071\n",
      "loss: 2.472006\n",
      "loss: 2.477260\n",
      "loss: 2.444297\n",
      "loss: 2.482561\n",
      "loss: 2.429371\n",
      "loss: 2.466416\n",
      "loss: 2.450115\n",
      "loss: 2.487216\n",
      "loss: 2.437449\n",
      "loss: 2.423798\n",
      "loss: 2.478597\n",
      "loss: 2.473897\n",
      "loss: 2.505871\n",
      "loss: 2.446059\n",
      "loss: 2.459543\n",
      "loss: 2.479271\n",
      "loss: 2.410325\n",
      "loss: 2.457420\n",
      "loss: 2.471800\n",
      "loss: 2.483755\n",
      "loss: 2.430821\n",
      "loss: 2.414425\n",
      "loss: 2.478202\n",
      "loss: 2.316368\n",
      "loss: 2.439054\n",
      "loss: 2.406472\n",
      "loss: 2.450270\n",
      "loss: 2.493196\n",
      "loss: 2.361424\n",
      "loss: 2.374611\n",
      "loss: 2.480397\n",
      "loss: 2.417824\n",
      "loss: 2.338966\n",
      "loss: 2.322778\n",
      "loss: 2.380939\n",
      "loss: 2.314275\n",
      "loss: 2.400326\n",
      "loss: 2.351437\n",
      "loss: 2.301612\n",
      "loss: 2.321000\n",
      "loss: 2.366635\n",
      "loss: 2.246655\n",
      "loss: 2.243696\n",
      "loss: 2.262435\n",
      "loss: 2.255786\n",
      "loss: 2.236611\n",
      "loss: 2.277653\n",
      "loss: 2.243341\n",
      "loss: 2.102447\n",
      "loss: 2.170855\n",
      "loss: 2.153470\n",
      "loss: 2.254069\n",
      "loss: 2.165622\n",
      "loss: 2.147983\n",
      "loss: 2.180481\n",
      "loss: 2.127270\n",
      "loss: 2.296898\n",
      "loss: 2.169131\n",
      "loss: 2.190694\n",
      "loss: 2.268639\n",
      "loss: 2.233963\n",
      "loss: 2.166974\n",
      "loss: 2.085169\n",
      "loss: 2.202929\n",
      "loss: 2.179805\n",
      "loss: 2.242615\n",
      "loss: 2.132898\n",
      "loss: 2.184515\n",
      "loss: 2.140695\n",
      "loss: 2.125443\n",
      "loss: 2.200838\n",
      "loss: 2.159601\n",
      "loss: 2.154045\n",
      "loss: 2.137177\n",
      "loss: 2.233244\n",
      "loss: 2.207167\n",
      "loss: 2.221232\n",
      "loss: 2.123867\n",
      "loss: 2.055891\n",
      "loss: 2.149876\n",
      "loss: 2.131982\n",
      "loss: 2.269360\n",
      "loss: 2.083444\n",
      "loss: 2.067334\n",
      "loss: 2.099697\n",
      "loss: 2.116652\n",
      "loss: 2.065010\n",
      "loss: 2.120998\n",
      "loss: 2.077044\n",
      "loss: 2.001086\n",
      "loss: 2.109384\n",
      "loss: 2.066086\n",
      "loss: 2.177319\n",
      "loss: 2.134153\n",
      "loss: 2.073205\n",
      "loss: 2.032766\n",
      "loss: 2.092354\n",
      "loss: 2.174543\n",
      "loss: 2.098072\n",
      "loss: 2.176463\n",
      "loss: 2.023679\n",
      "loss: 2.029908\n",
      "loss: 2.048559\n",
      "loss: 2.057289\n",
      "loss: 2.075769\n",
      "loss: 2.104228\n",
      "loss: 1.972615\n",
      "loss: 2.019818\n",
      "loss: 1.998261\n",
      "loss: 2.060541\n",
      "loss: 2.084821\n",
      "loss: 1.992523\n",
      "loss: 2.070664\n",
      "loss: 1.936264\n",
      "loss: 1.996273\n",
      "loss: 2.042696\n",
      "loss: 1.893243\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.498679 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.067434\n",
      "loss: 2.049275\n",
      "loss: 1.942708\n",
      "loss: 1.895033\n",
      "loss: 2.025125\n",
      "loss: 2.052135\n",
      "loss: 2.032553\n",
      "loss: 1.919967\n",
      "loss: 1.966359\n",
      "loss: 2.124532\n",
      "loss: 2.084947\n",
      "loss: 2.077354\n",
      "loss: 1.929241\n",
      "loss: 1.953550\n",
      "loss: 1.928469\n",
      "loss: 1.958395\n",
      "loss: 1.887022\n",
      "loss: 1.982492\n",
      "loss: 1.912165\n",
      "loss: 2.010717\n",
      "loss: 1.936550\n",
      "loss: 1.834640\n",
      "loss: 2.018976\n",
      "loss: 1.866993\n",
      "loss: 1.913962\n",
      "loss: 1.889968\n",
      "loss: 1.866738\n",
      "loss: 1.912540\n",
      "loss: 2.001692\n",
      "loss: 1.868995\n",
      "loss: 1.968422\n",
      "loss: 1.805130\n",
      "loss: 1.898583\n",
      "loss: 1.871879\n",
      "loss: 1.858458\n",
      "loss: 1.852660\n",
      "loss: 1.924838\n",
      "loss: 1.828357\n",
      "loss: 1.901953\n",
      "loss: 1.909775\n",
      "loss: 1.920398\n",
      "loss: 1.860306\n",
      "loss: 1.818722\n",
      "loss: 1.836198\n",
      "loss: 1.873725\n",
      "loss: 1.827716\n",
      "loss: 1.829708\n",
      "loss: 1.856857\n",
      "loss: 1.787615\n",
      "loss: 1.857134\n",
      "loss: 1.852299\n",
      "loss: 1.807330\n",
      "loss: 1.845574\n",
      "loss: 1.768359\n",
      "loss: 1.658430\n",
      "loss: 1.799607\n",
      "loss: 1.774626\n",
      "loss: 1.673356\n",
      "loss: 1.809485\n",
      "loss: 1.671117\n",
      "loss: 1.562470\n",
      "loss: 1.795446\n",
      "loss: 1.798876\n",
      "loss: 1.761340\n",
      "loss: 1.761759\n",
      "loss: 1.753942\n",
      "loss: 1.660111\n",
      "loss: 1.664417\n",
      "loss: 1.771011\n",
      "loss: 1.729291\n",
      "loss: 1.690059\n",
      "loss: 1.680292\n",
      "loss: 1.793472\n",
      "loss: 1.614748\n",
      "loss: 1.703681\n",
      "loss: 1.890400\n",
      "loss: 1.745286\n",
      "loss: 1.639235\n",
      "loss: 1.697669\n",
      "loss: 1.743320\n",
      "loss: 1.731494\n",
      "loss: 1.782393\n",
      "loss: 1.719203\n",
      "loss: 1.626809\n",
      "loss: 1.716765\n",
      "loss: 1.717018\n",
      "loss: 1.705055\n",
      "loss: 1.625303\n",
      "loss: 1.699810\n",
      "loss: 1.795642\n",
      "loss: 1.667277\n",
      "loss: 1.628309\n",
      "loss: 1.677871\n",
      "loss: 1.639868\n",
      "loss: 1.576968\n",
      "loss: 1.736735\n",
      "loss: 1.826013\n",
      "loss: 1.706848\n",
      "loss: 1.788277\n",
      "loss: 1.704388\n",
      "loss: 1.727103\n",
      "loss: 1.699803\n",
      "loss: 1.826507\n",
      "loss: 1.825295\n",
      "loss: 1.703819\n",
      "loss: 1.699259\n",
      "loss: 1.753306\n",
      "loss: 1.752243\n",
      "loss: 1.649026\n",
      "loss: 1.486799\n",
      "loss: 1.719969\n",
      "loss: 1.699514\n",
      "loss: 1.630860\n",
      "loss: 1.719678\n",
      "loss: 1.778666\n",
      "loss: 1.589288\n",
      "loss: 1.552772\n",
      "loss: 1.611806\n",
      "loss: 1.599876\n",
      "loss: 1.632108\n",
      "loss: 1.547571\n",
      "loss: 1.765537\n",
      "loss: 1.711137\n",
      "loss: 1.668396\n",
      "loss: 1.579101\n",
      "loss: 1.605265\n",
      "loss: 1.530988\n",
      "loss: 1.701186\n",
      "loss: 1.531083\n",
      "loss: 1.494093\n",
      "loss: 1.507109\n",
      "loss: 1.568155\n",
      "loss: 1.588885\n",
      "loss: 1.541738\n",
      "loss: 1.616023\n",
      "loss: 1.555624\n",
      "loss: 1.630540\n",
      "loss: 1.691330\n",
      "loss: 1.706145\n",
      "loss: 1.674260\n",
      "loss: 1.468073\n",
      "loss: 1.569745\n",
      "loss: 1.663412\n",
      "loss: 1.410940\n",
      "loss: 1.512904\n",
      "loss: 1.420282\n",
      "loss: 1.547791\n",
      "loss: 1.527833\n",
      "loss: 1.489901\n",
      "loss: 1.540542\n",
      "loss: 1.506536\n",
      "loss: 1.595032\n",
      "loss: 1.499817\n",
      "loss: 1.512585\n",
      "loss: 1.492983\n",
      "loss: 1.511824\n",
      "loss: 1.517519\n",
      "loss: 1.342228\n",
      "loss: 1.588489\n",
      "loss: 1.625417\n",
      "loss: 1.480878\n",
      "loss: 1.637732\n",
      "loss: 1.660584\n",
      "loss: 1.468928\n",
      "loss: 1.594270\n",
      "loss: 1.603396\n",
      "loss: 1.598965\n",
      "loss: 1.463207\n",
      "loss: 1.523224\n",
      "loss: 1.500917\n",
      "loss: 1.528727\n",
      "loss: 1.391053\n",
      "loss: 1.464383\n",
      "loss: 1.484164\n",
      "loss: 1.636161\n",
      "loss: 1.406088\n",
      "loss: 1.503001\n",
      "loss: 1.502754\n",
      "loss: 1.520435\n",
      "loss: 1.626718\n",
      "loss: 1.462222\n",
      "loss: 1.545921\n",
      "loss: 1.433822\n",
      "loss: 1.477383\n",
      "loss: 1.517804\n",
      "loss: 1.480030\n",
      "loss: 1.557647\n",
      "loss: 1.355341\n",
      "loss: 1.521570\n",
      "loss: 1.546196\n",
      "loss: 1.301008\n",
      "loss: 1.505751\n",
      "loss: 1.590751\n",
      "loss: 1.472756\n",
      "loss: 1.423000\n",
      "loss: 1.574768\n",
      "loss: 1.519804\n",
      "loss: 1.556802\n",
      "loss: 1.565902\n",
      "loss: 1.450542\n",
      "loss: 1.446176\n",
      "loss: 1.347360\n",
      "loss: 1.462988\n",
      "loss: 1.425843\n",
      "loss: 1.625214\n",
      "loss: 1.466680\n",
      "loss: 1.419902\n",
      "loss: 1.570715\n",
      "loss: 1.292357\n",
      "loss: 1.460849\n",
      "loss: 1.395405\n",
      "loss: 1.333270\n",
      "loss: 1.431759\n",
      "loss: 1.517939\n",
      "loss: 1.544704\n",
      "loss: 1.424208\n",
      "loss: 1.411066\n",
      "loss: 1.337770\n",
      "loss: 1.473693\n",
      "loss: 1.341835\n",
      "loss: 1.386767\n",
      "loss: 1.454615\n",
      "loss: 1.348921\n",
      "loss: 1.578746\n",
      "loss: 1.262737\n",
      "loss: 1.344085\n",
      "loss: 1.364443\n",
      "loss: 1.368218\n",
      "loss: 1.410209\n",
      "loss: 1.385670\n",
      "loss: 1.265957\n",
      "loss: 1.289843\n",
      "loss: 1.322581\n",
      "loss: 1.378408\n",
      "loss: 1.271390\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.807862 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.425068\n",
      "loss: 1.226077\n",
      "loss: 1.232510\n",
      "loss: 1.267052\n",
      "loss: 1.330090\n",
      "loss: 1.520820\n",
      "loss: 1.381290\n",
      "loss: 1.374042\n",
      "loss: 1.352700\n",
      "loss: 1.262379\n",
      "loss: 1.256442\n",
      "loss: 1.361210\n",
      "loss: 1.418178\n",
      "loss: 1.231868\n",
      "loss: 1.353356\n",
      "loss: 1.280002\n",
      "loss: 1.335223\n",
      "loss: 1.322761\n",
      "loss: 1.523014\n",
      "loss: 1.345134\n",
      "loss: 1.321581\n",
      "loss: 1.264984\n",
      "loss: 1.249351\n",
      "loss: 1.335821\n",
      "loss: 1.264242\n",
      "loss: 1.342585\n",
      "loss: 1.380587\n",
      "loss: 1.224738\n",
      "loss: 1.380122\n",
      "loss: 1.359116\n",
      "loss: 1.363627\n",
      "loss: 1.180692\n",
      "loss: 1.331718\n",
      "loss: 1.272168\n",
      "loss: 1.468049\n",
      "loss: 1.466407\n",
      "loss: 1.440379\n",
      "loss: 1.376300\n",
      "loss: 1.237789\n",
      "loss: 1.517147\n",
      "loss: 1.346002\n",
      "loss: 1.313923\n",
      "loss: 1.442662\n",
      "loss: 1.263981\n",
      "loss: 1.114906\n",
      "loss: 1.154053\n",
      "loss: 1.233360\n",
      "loss: 1.289928\n",
      "loss: 1.274822\n",
      "loss: 1.297033\n",
      "loss: 1.158498\n",
      "loss: 1.218551\n",
      "loss: 1.288197\n",
      "loss: 1.187125\n",
      "loss: 1.162626\n",
      "loss: 1.230042\n",
      "loss: 1.257168\n",
      "loss: 1.299468\n",
      "loss: 1.343464\n",
      "loss: 1.263584\n",
      "loss: 1.241690\n",
      "loss: 1.253945\n",
      "loss: 1.215688\n",
      "loss: 1.189261\n",
      "loss: 1.221932\n",
      "loss: 1.191642\n",
      "loss: 1.331196\n",
      "loss: 1.231413\n",
      "loss: 1.192155\n",
      "loss: 1.308152\n",
      "loss: 1.278254\n",
      "loss: 1.392044\n",
      "loss: 1.128356\n",
      "loss: 1.397437\n",
      "loss: 1.238272\n",
      "loss: 1.213848\n",
      "loss: 1.127619\n",
      "loss: 1.248448\n",
      "loss: 1.294784\n",
      "loss: 1.151229\n",
      "loss: 1.125888\n",
      "loss: 1.245950\n",
      "loss: 1.106228\n",
      "loss: 1.182008\n",
      "loss: 1.192189\n",
      "loss: 1.242098\n",
      "loss: 1.098315\n",
      "loss: 1.113086\n",
      "loss: 1.085034\n",
      "loss: 1.143361\n",
      "loss: 1.216531\n",
      "loss: 1.232136\n",
      "loss: 1.210687\n",
      "loss: 1.213333\n",
      "loss: 1.015441\n",
      "loss: 1.102324\n",
      "loss: 1.347740\n",
      "loss: 1.184963\n",
      "loss: 1.222274\n",
      "loss: 1.193573\n",
      "loss: 1.226778\n",
      "loss: 1.114532\n",
      "loss: 1.223322\n",
      "loss: 1.049812\n",
      "loss: 1.125251\n",
      "loss: 1.095193\n",
      "loss: 1.242704\n",
      "loss: 1.314350\n",
      "loss: 1.176335\n",
      "loss: 1.251261\n",
      "loss: 1.106130\n",
      "loss: 1.220310\n",
      "loss: 1.168609\n",
      "loss: 1.242008\n",
      "loss: 1.058222\n",
      "loss: 1.173107\n",
      "loss: 1.028048\n",
      "loss: 1.248096\n",
      "loss: 1.286318\n",
      "loss: 1.162401\n",
      "loss: 1.165893\n",
      "loss: 1.144088\n",
      "loss: 1.110508\n",
      "loss: 1.043335\n",
      "loss: 1.146338\n",
      "loss: 1.048231\n",
      "loss: 1.107310\n",
      "loss: 1.160060\n",
      "loss: 1.091479\n",
      "loss: 1.074148\n",
      "loss: 1.075964\n",
      "loss: 1.076012\n",
      "loss: 1.046491\n",
      "loss: 1.002087\n",
      "loss: 1.171208\n",
      "loss: 1.302244\n",
      "loss: 1.276507\n",
      "loss: 1.073189\n",
      "loss: 1.104551\n",
      "loss: 1.327027\n",
      "loss: 1.016956\n",
      "loss: 0.989532\n",
      "loss: 1.153265\n",
      "loss: 1.282966\n",
      "loss: 1.108106\n",
      "loss: 1.118199\n",
      "loss: 1.081921\n",
      "loss: 1.023108\n",
      "loss: 1.030410\n",
      "loss: 0.994372\n",
      "loss: 0.987021\n",
      "loss: 1.120463\n",
      "loss: 1.045067\n",
      "loss: 1.075971\n",
      "loss: 1.114700\n",
      "loss: 1.209196\n",
      "loss: 1.160153\n",
      "loss: 1.088225\n",
      "loss: 0.998122\n",
      "loss: 1.201769\n",
      "loss: 1.104249\n",
      "loss: 1.086739\n",
      "loss: 1.139829\n",
      "loss: 1.284305\n",
      "loss: 1.134844\n",
      "loss: 1.207420\n",
      "loss: 0.980441\n",
      "loss: 0.897599\n",
      "loss: 1.263896\n",
      "loss: 1.108695\n",
      "loss: 0.984928\n",
      "loss: 1.259218\n",
      "loss: 0.973682\n",
      "loss: 1.027847\n",
      "loss: 0.989966\n",
      "loss: 0.961839\n",
      "loss: 1.111044\n",
      "loss: 1.079877\n",
      "loss: 0.990865\n",
      "loss: 1.231615\n",
      "loss: 0.989164\n",
      "loss: 1.133718\n",
      "loss: 1.040801\n",
      "loss: 1.225116\n",
      "loss: 1.012764\n",
      "loss: 1.164088\n",
      "loss: 1.139655\n",
      "loss: 1.202183\n",
      "loss: 1.028931\n",
      "loss: 0.982966\n",
      "loss: 1.001427\n",
      "loss: 0.990199\n",
      "loss: 1.129139\n",
      "loss: 1.156150\n",
      "loss: 1.118128\n",
      "loss: 0.950065\n",
      "loss: 1.169966\n",
      "loss: 1.047511\n",
      "loss: 0.997831\n",
      "loss: 1.110402\n",
      "loss: 0.996176\n",
      "loss: 0.981148\n",
      "loss: 1.112703\n",
      "loss: 0.935601\n",
      "loss: 0.975198\n",
      "loss: 0.966070\n",
      "loss: 1.057295\n",
      "loss: 1.013679\n",
      "loss: 1.112526\n",
      "loss: 1.054836\n",
      "loss: 1.277238\n",
      "loss: 1.100188\n",
      "loss: 1.013019\n",
      "loss: 1.082552\n",
      "loss: 1.016125\n",
      "loss: 1.104962\n",
      "loss: 1.059626\n",
      "loss: 1.022230\n",
      "loss: 1.172806\n",
      "loss: 1.208505\n",
      "loss: 1.117759\n",
      "loss: 1.009380\n",
      "loss: 0.877852\n",
      "loss: 1.066609\n",
      "loss: 0.976555\n",
      "loss: 1.034740\n",
      "loss: 1.086156\n",
      "loss: 0.877938\n",
      "loss: 1.146842\n",
      "loss: 1.095382\n",
      "loss: 1.029225\n",
      "loss: 1.077927\n",
      "loss: 1.010505\n",
      "loss: 1.014272\n",
      "loss: 1.290977\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.635004 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.054262\n",
      "loss: 1.137374\n",
      "loss: 1.117312\n",
      "loss: 1.159634\n",
      "loss: 1.041167\n",
      "loss: 1.146492\n",
      "loss: 1.090775\n",
      "loss: 1.168949\n",
      "loss: 0.997575\n",
      "loss: 1.077105\n",
      "loss: 1.075001\n",
      "loss: 1.073581\n",
      "loss: 1.025158\n",
      "loss: 1.123921\n",
      "loss: 1.015911\n",
      "loss: 1.255186\n",
      "loss: 1.070735\n",
      "loss: 0.943039\n",
      "loss: 1.017045\n",
      "loss: 1.142833\n",
      "loss: 0.989512\n",
      "loss: 1.121850\n",
      "loss: 1.187611\n",
      "loss: 1.208698\n",
      "loss: 1.018779\n",
      "loss: 1.097741\n",
      "loss: 1.065703\n",
      "loss: 1.211371\n",
      "loss: 1.133391\n",
      "loss: 0.957169\n",
      "loss: 1.137453\n",
      "loss: 1.125356\n",
      "loss: 1.106650\n",
      "loss: 0.987784\n",
      "loss: 1.117452\n",
      "loss: 0.850257\n",
      "loss: 1.035267\n",
      "loss: 1.101387\n",
      "loss: 0.945113\n",
      "loss: 1.243558\n",
      "loss: 0.902770\n",
      "loss: 0.997436\n",
      "loss: 1.095572\n",
      "loss: 1.132735\n",
      "loss: 1.059948\n",
      "loss: 0.923829\n",
      "loss: 0.825960\n",
      "loss: 1.052199\n",
      "loss: 0.905715\n",
      "loss: 1.205506\n",
      "loss: 1.077424\n",
      "loss: 1.155315\n",
      "loss: 1.061910\n",
      "loss: 0.969492\n",
      "loss: 1.057539\n",
      "loss: 0.991104\n",
      "loss: 0.998948\n",
      "loss: 1.012956\n",
      "loss: 1.149242\n",
      "loss: 0.915031\n",
      "loss: 0.971969\n",
      "loss: 1.018343\n",
      "loss: 0.990729\n",
      "loss: 1.114878\n",
      "loss: 1.039194\n",
      "loss: 1.140117\n",
      "loss: 0.884172\n",
      "loss: 0.936526\n",
      "loss: 1.035423\n",
      "loss: 1.022747\n",
      "loss: 1.129884\n",
      "loss: 1.002599\n",
      "loss: 1.007755\n",
      "loss: 0.954904\n",
      "loss: 0.991504\n",
      "loss: 0.970117\n",
      "loss: 1.174720\n",
      "loss: 0.773415\n",
      "loss: 0.992855\n",
      "loss: 0.931751\n",
      "loss: 1.045815\n",
      "loss: 0.925155\n",
      "loss: 0.972790\n",
      "loss: 1.017466\n",
      "loss: 1.068767\n",
      "loss: 1.030247\n",
      "loss: 0.884207\n",
      "loss: 1.049317\n",
      "loss: 0.936741\n",
      "loss: 0.911387\n",
      "loss: 0.788022\n",
      "loss: 0.925807\n",
      "loss: 0.973266\n",
      "loss: 1.080262\n",
      "loss: 1.056649\n",
      "loss: 1.142656\n",
      "loss: 0.791103\n",
      "loss: 0.997734\n",
      "loss: 0.945830\n",
      "loss: 1.037134\n",
      "loss: 0.995026\n",
      "loss: 1.014933\n",
      "loss: 0.863393\n",
      "loss: 1.143367\n",
      "loss: 0.844940\n",
      "loss: 1.012704\n",
      "loss: 1.007339\n",
      "loss: 0.935122\n",
      "loss: 0.995283\n",
      "loss: 0.967487\n",
      "loss: 0.967006\n",
      "loss: 0.966506\n",
      "loss: 0.903734\n",
      "loss: 1.007686\n",
      "loss: 0.812283\n",
      "loss: 1.056551\n",
      "loss: 0.837394\n",
      "loss: 0.867739\n",
      "loss: 0.834148\n",
      "loss: 0.951944\n",
      "loss: 1.004922\n",
      "loss: 0.895903\n",
      "loss: 0.970692\n",
      "loss: 0.929640\n",
      "loss: 1.129938\n",
      "loss: 0.941857\n",
      "loss: 1.032369\n",
      "loss: 0.961752\n",
      "loss: 0.911454\n",
      "loss: 0.979319\n",
      "loss: 1.123394\n",
      "loss: 1.046910\n",
      "loss: 0.867907\n",
      "loss: 0.979929\n",
      "loss: 1.107945\n",
      "loss: 0.948305\n",
      "loss: 0.883909\n",
      "loss: 1.114306\n",
      "loss: 1.208224\n",
      "loss: 1.046331\n",
      "loss: 0.949173\n",
      "loss: 0.897384\n",
      "loss: 0.914593\n",
      "loss: 1.080084\n",
      "loss: 0.979158\n",
      "loss: 0.950817\n",
      "loss: 0.880738\n",
      "loss: 0.826428\n",
      "loss: 0.862190\n",
      "loss: 1.008770\n",
      "loss: 1.036588\n",
      "loss: 1.010438\n",
      "loss: 0.945189\n",
      "loss: 1.027801\n",
      "loss: 0.816925\n",
      "loss: 0.829601\n",
      "loss: 0.838407\n",
      "loss: 0.944068\n",
      "loss: 0.896610\n",
      "loss: 0.947312\n",
      "loss: 1.085548\n",
      "loss: 0.889772\n",
      "loss: 0.860318\n",
      "loss: 0.829224\n",
      "loss: 0.798784\n",
      "loss: 1.010792\n",
      "loss: 0.934507\n",
      "loss: 0.916026\n",
      "loss: 0.857318\n",
      "loss: 0.933772\n",
      "loss: 0.855376\n",
      "loss: 0.928020\n",
      "loss: 0.918170\n",
      "loss: 0.924041\n",
      "loss: 0.926268\n",
      "loss: 1.063438\n",
      "loss: 0.955232\n",
      "loss: 0.982252\n",
      "loss: 0.978156\n",
      "loss: 0.971808\n",
      "loss: 0.843946\n",
      "loss: 0.867783\n",
      "loss: 0.944637\n",
      "loss: 0.908196\n",
      "loss: 0.971085\n",
      "loss: 0.864923\n",
      "loss: 0.931218\n",
      "loss: 0.863226\n",
      "loss: 0.928765\n",
      "loss: 0.934831\n",
      "loss: 0.950318\n",
      "loss: 1.019849\n",
      "loss: 0.909045\n",
      "loss: 0.896594\n",
      "loss: 0.936630\n",
      "loss: 0.929016\n",
      "loss: 0.821115\n",
      "loss: 1.028820\n",
      "loss: 0.887354\n",
      "loss: 0.864507\n",
      "loss: 0.917235\n",
      "loss: 0.987087\n",
      "loss: 0.880859\n",
      "loss: 0.837904\n",
      "loss: 1.030100\n",
      "loss: 0.899185\n",
      "loss: 0.985077\n",
      "loss: 1.064267\n",
      "loss: 0.783648\n",
      "loss: 0.887600\n",
      "loss: 0.880291\n",
      "loss: 0.893847\n",
      "loss: 1.064098\n",
      "loss: 1.002799\n",
      "loss: 0.976985\n",
      "loss: 0.947724\n",
      "loss: 0.907989\n",
      "loss: 0.971445\n",
      "loss: 0.908654\n",
      "loss: 0.838747\n",
      "loss: 0.912106\n",
      "loss: 0.990193\n",
      "loss: 1.104694\n",
      "loss: 0.946316\n",
      "loss: 0.972800\n",
      "loss: 1.001186\n",
      "loss: 0.816308\n",
      "loss: 0.990822\n",
      "loss: 0.944107\n",
      "loss: 0.789368\n",
      "loss: 0.959777\n",
      "loss: 1.000982\n",
      "loss: 0.866558\n",
      "loss: 0.970215\n",
      "loss: 1.008786\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.546676 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.983339\n",
      "loss: 1.019762\n",
      "loss: 0.925734\n",
      "loss: 0.861253\n",
      "loss: 0.989491\n",
      "loss: 0.904803\n",
      "loss: 0.850172\n",
      "loss: 1.007927\n",
      "loss: 1.029896\n",
      "loss: 0.960003\n",
      "loss: 1.133797\n",
      "loss: 0.967018\n",
      "loss: 0.891659\n",
      "loss: 0.993485\n",
      "loss: 1.134356\n",
      "loss: 0.903027\n",
      "loss: 0.817472\n",
      "loss: 1.102855\n",
      "loss: 0.871205\n",
      "loss: 0.925045\n",
      "loss: 0.924850\n",
      "loss: 0.823554\n",
      "loss: 1.190676\n",
      "loss: 0.772919\n",
      "loss: 0.851280\n",
      "loss: 1.036774\n",
      "loss: 0.975775\n",
      "loss: 0.979297\n",
      "loss: 0.846312\n",
      "loss: 0.807593\n",
      "loss: 1.009240\n",
      "loss: 0.925666\n",
      "loss: 0.943429\n",
      "loss: 0.920821\n",
      "loss: 0.872347\n",
      "loss: 0.807068\n",
      "loss: 0.836497\n",
      "loss: 0.883335\n",
      "loss: 0.892002\n",
      "loss: 1.060179\n",
      "loss: 0.842437\n",
      "loss: 1.009050\n",
      "loss: 1.029649\n",
      "loss: 0.934916\n",
      "loss: 0.977174\n",
      "loss: 0.978066\n",
      "loss: 0.861887\n",
      "loss: 0.913521\n",
      "loss: 0.802094\n",
      "loss: 1.055642\n",
      "loss: 0.826029\n",
      "loss: 0.956516\n",
      "loss: 0.782082\n",
      "loss: 1.003788\n",
      "loss: 0.962878\n",
      "loss: 1.056913\n",
      "loss: 0.832421\n",
      "loss: 1.058959\n",
      "loss: 1.004169\n",
      "loss: 1.089884\n",
      "loss: 0.843934\n",
      "loss: 0.895024\n",
      "loss: 1.003617\n",
      "loss: 0.974255\n",
      "loss: 1.014470\n",
      "loss: 0.846190\n",
      "loss: 1.073643\n",
      "loss: 0.968707\n",
      "loss: 0.900989\n",
      "loss: 0.966780\n",
      "loss: 0.860080\n",
      "loss: 0.878528\n",
      "loss: 0.895290\n",
      "loss: 1.163028\n",
      "loss: 0.821449\n",
      "loss: 0.840204\n",
      "loss: 0.952428\n",
      "loss: 0.886651\n",
      "loss: 1.022825\n",
      "loss: 1.092304\n",
      "loss: 0.783339\n",
      "loss: 0.866076\n",
      "loss: 0.821302\n",
      "loss: 0.807528\n",
      "loss: 0.974237\n",
      "loss: 0.912165\n",
      "loss: 1.037019\n",
      "loss: 0.891532\n",
      "loss: 0.909830\n",
      "loss: 0.891947\n",
      "loss: 1.027272\n",
      "loss: 0.859488\n",
      "loss: 0.944580\n",
      "loss: 0.846610\n",
      "loss: 1.124488\n",
      "loss: 0.943537\n",
      "loss: 1.083001\n",
      "loss: 0.820880\n",
      "loss: 0.910326\n",
      "loss: 0.789717\n",
      "loss: 0.763554\n",
      "loss: 1.009545\n",
      "loss: 0.979889\n",
      "loss: 0.807810\n",
      "loss: 0.803806\n",
      "loss: 0.758436\n",
      "loss: 0.877757\n",
      "loss: 0.923692\n",
      "loss: 0.937128\n",
      "loss: 1.089015\n",
      "loss: 0.716075\n",
      "loss: 0.948273\n",
      "loss: 0.869639\n",
      "loss: 0.942455\n",
      "loss: 1.056172\n",
      "loss: 1.115645\n",
      "loss: 0.787274\n",
      "loss: 0.910129\n",
      "loss: 0.814179\n",
      "loss: 0.908077\n",
      "loss: 0.837639\n",
      "loss: 0.906716\n",
      "loss: 0.970694\n",
      "loss: 0.929066\n",
      "loss: 0.910939\n",
      "loss: 0.960291\n",
      "loss: 0.927072\n",
      "loss: 0.907213\n",
      "loss: 1.074648\n",
      "loss: 0.834792\n",
      "loss: 0.921386\n",
      "loss: 0.840949\n",
      "loss: 0.756332\n",
      "loss: 0.886950\n",
      "loss: 1.054819\n",
      "loss: 0.697158\n",
      "loss: 0.707817\n",
      "loss: 0.798460\n",
      "loss: 0.917654\n",
      "loss: 0.977451\n",
      "loss: 0.874297\n",
      "loss: 0.941406\n",
      "loss: 0.894428\n",
      "loss: 0.900881\n",
      "loss: 0.909307\n",
      "loss: 0.809753\n",
      "loss: 0.793033\n",
      "loss: 1.009125\n",
      "loss: 0.761775\n",
      "loss: 0.952794\n",
      "loss: 0.734543\n",
      "loss: 0.863838\n",
      "loss: 0.833629\n",
      "loss: 1.115368\n",
      "loss: 0.914733\n",
      "loss: 1.118239\n",
      "loss: 0.968667\n",
      "loss: 0.821121\n",
      "loss: 0.793089\n",
      "loss: 0.891397\n",
      "loss: 0.943239\n",
      "loss: 0.898622\n",
      "loss: 0.878163\n",
      "loss: 0.852587\n",
      "loss: 0.812305\n",
      "loss: 0.835624\n",
      "loss: 0.939815\n",
      "loss: 0.869218\n",
      "loss: 0.761623\n",
      "loss: 1.013901\n",
      "loss: 0.797127\n",
      "loss: 0.834001\n",
      "loss: 0.935110\n",
      "loss: 0.719868\n",
      "loss: 0.920147\n",
      "loss: 0.955051\n",
      "loss: 0.861301\n",
      "loss: 0.864579\n",
      "loss: 0.812972\n",
      "loss: 0.928265\n",
      "loss: 0.923265\n",
      "loss: 0.731423\n",
      "loss: 0.843961\n",
      "loss: 0.928298\n",
      "loss: 0.903122\n",
      "loss: 0.902815\n",
      "loss: 0.726011\n",
      "loss: 0.918373\n",
      "loss: 0.787526\n",
      "loss: 0.864444\n",
      "loss: 0.922975\n",
      "loss: 1.057437\n",
      "loss: 0.819850\n",
      "loss: 0.796252\n",
      "loss: 0.879043\n",
      "loss: 0.636558\n",
      "loss: 0.969597\n",
      "loss: 0.935338\n",
      "loss: 0.871955\n",
      "loss: 1.041361\n",
      "loss: 0.733403\n",
      "loss: 0.991384\n",
      "loss: 0.873134\n",
      "loss: 0.937829\n",
      "loss: 0.830314\n",
      "loss: 0.876963\n",
      "loss: 0.889110\n",
      "loss: 0.783469\n",
      "loss: 0.883052\n",
      "loss: 0.957540\n",
      "loss: 0.699194\n",
      "loss: 0.913870\n",
      "loss: 1.001081\n",
      "loss: 0.973768\n",
      "loss: 0.789053\n",
      "loss: 0.823175\n",
      "loss: 0.889424\n",
      "loss: 0.715242\n",
      "loss: 0.775806\n",
      "loss: 0.962641\n",
      "loss: 0.866941\n",
      "loss: 0.762404\n",
      "loss: 0.981591\n",
      "loss: 0.991642\n",
      "loss: 0.821176\n",
      "loss: 0.808674\n",
      "loss: 0.808939\n",
      "loss: 0.912383\n",
      "loss: 0.850860\n",
      "loss: 0.946746\n",
      "loss: 0.902664\n",
      "loss: 0.805387\n",
      "loss: 0.769946\n",
      "loss: 0.813818\n",
      "loss: 0.778640\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.504758 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.860890\n",
      "loss: 0.771853\n",
      "loss: 0.819096\n",
      "loss: 0.897324\n",
      "loss: 0.996435\n",
      "loss: 0.850345\n",
      "loss: 0.788893\n",
      "loss: 1.011351\n",
      "loss: 0.865629\n",
      "loss: 0.994147\n",
      "loss: 0.837496\n",
      "loss: 0.746688\n",
      "loss: 0.940305\n",
      "loss: 0.907776\n",
      "loss: 0.794648\n",
      "loss: 0.713293\n",
      "loss: 0.879144\n",
      "loss: 0.901498\n",
      "loss: 0.720035\n",
      "loss: 0.884291\n",
      "loss: 0.876414\n",
      "loss: 0.880479\n",
      "loss: 0.923597\n",
      "loss: 0.740018\n",
      "loss: 0.950179\n",
      "loss: 0.896719\n",
      "loss: 0.831531\n",
      "loss: 0.830915\n",
      "loss: 0.851822\n",
      "loss: 0.939759\n",
      "loss: 1.123485\n",
      "loss: 0.864075\n",
      "loss: 0.975844\n",
      "loss: 0.974773\n",
      "loss: 0.935233\n",
      "loss: 0.897325\n",
      "loss: 0.857126\n",
      "loss: 0.778634\n",
      "loss: 0.601762\n",
      "loss: 0.793198\n",
      "loss: 0.834515\n",
      "loss: 0.718278\n",
      "loss: 0.861947\n",
      "loss: 0.871544\n",
      "loss: 0.740961\n",
      "loss: 0.880656\n",
      "loss: 0.893741\n",
      "loss: 0.809149\n",
      "loss: 0.952054\n",
      "loss: 0.854778\n",
      "loss: 0.894249\n",
      "loss: 0.766036\n",
      "loss: 0.892445\n",
      "loss: 0.973741\n",
      "loss: 1.070043\n",
      "loss: 1.003777\n",
      "loss: 0.774195\n",
      "loss: 0.745594\n",
      "loss: 0.870473\n",
      "loss: 0.943955\n",
      "loss: 0.790488\n",
      "loss: 0.942873\n",
      "loss: 0.755950\n",
      "loss: 0.641191\n",
      "loss: 0.852269\n",
      "loss: 0.683330\n",
      "loss: 0.988368\n",
      "loss: 0.923206\n",
      "loss: 0.705762\n",
      "loss: 0.759497\n",
      "loss: 1.024104\n",
      "loss: 0.732663\n",
      "loss: 0.819134\n",
      "loss: 0.945146\n",
      "loss: 0.894657\n",
      "loss: 0.866383\n",
      "loss: 0.811401\n",
      "loss: 0.728906\n",
      "loss: 0.951440\n",
      "loss: 0.890190\n",
      "loss: 0.798500\n",
      "loss: 0.780118\n",
      "loss: 0.859023\n",
      "loss: 0.828257\n",
      "loss: 0.871266\n",
      "loss: 1.025896\n",
      "loss: 0.944918\n",
      "loss: 0.791665\n",
      "loss: 0.836226\n",
      "loss: 0.783164\n",
      "loss: 0.785097\n",
      "loss: 0.940348\n",
      "loss: 0.816908\n",
      "loss: 0.734903\n",
      "loss: 0.808644\n",
      "loss: 0.968149\n",
      "loss: 0.602471\n",
      "loss: 0.853637\n",
      "loss: 0.812995\n",
      "loss: 0.927344\n",
      "loss: 0.891361\n",
      "loss: 0.724496\n",
      "loss: 0.815750\n",
      "loss: 0.624958\n",
      "loss: 0.735744\n",
      "loss: 0.785451\n",
      "loss: 0.809371\n",
      "loss: 0.755365\n",
      "loss: 0.775065\n",
      "loss: 0.826209\n",
      "loss: 0.798933\n",
      "loss: 0.846186\n",
      "loss: 0.974279\n",
      "loss: 0.897025\n",
      "loss: 0.825734\n",
      "loss: 0.942943\n",
      "loss: 0.768610\n",
      "loss: 0.739728\n",
      "loss: 0.901501\n",
      "loss: 0.844001\n",
      "loss: 0.820347\n",
      "loss: 0.665191\n",
      "loss: 0.734177\n",
      "loss: 0.839334\n",
      "loss: 0.892675\n",
      "loss: 0.751720\n",
      "loss: 0.702767\n",
      "loss: 0.659066\n",
      "loss: 0.835560\n",
      "loss: 0.980352\n",
      "loss: 0.804888\n",
      "loss: 0.890857\n",
      "loss: 0.863227\n",
      "loss: 0.768826\n",
      "loss: 0.823022\n",
      "loss: 0.808062\n",
      "loss: 0.828858\n",
      "loss: 0.754042\n",
      "loss: 0.877569\n",
      "loss: 0.795073\n",
      "loss: 0.861236\n",
      "loss: 0.762721\n",
      "loss: 0.893913\n",
      "loss: 0.766945\n",
      "loss: 0.845042\n",
      "loss: 0.776442\n",
      "loss: 0.843529\n",
      "loss: 0.801792\n",
      "loss: 0.734026\n",
      "loss: 0.861346\n",
      "loss: 0.916250\n",
      "loss: 0.963731\n",
      "loss: 0.615543\n",
      "loss: 0.921490\n",
      "loss: 0.748300\n",
      "loss: 0.856864\n",
      "loss: 0.754571\n",
      "loss: 0.801618\n",
      "loss: 1.011531\n",
      "loss: 0.852403\n",
      "loss: 0.801445\n",
      "loss: 0.842513\n",
      "loss: 0.731969\n",
      "loss: 0.751443\n",
      "loss: 0.783162\n",
      "loss: 0.778845\n",
      "loss: 0.938858\n",
      "loss: 0.996178\n",
      "loss: 0.899509\n",
      "loss: 0.899918\n",
      "loss: 0.803532\n",
      "loss: 0.869374\n",
      "loss: 0.687792\n",
      "loss: 0.737845\n",
      "loss: 0.685631\n",
      "loss: 0.796175\n",
      "loss: 0.776617\n",
      "loss: 0.775331\n",
      "loss: 0.764275\n",
      "loss: 0.777037\n",
      "loss: 0.800043\n",
      "loss: 0.664187\n",
      "loss: 0.923518\n",
      "loss: 0.732681\n",
      "loss: 0.610352\n",
      "loss: 0.841989\n",
      "loss: 0.932810\n",
      "loss: 0.845324\n",
      "loss: 0.676283\n",
      "loss: 0.747477\n",
      "loss: 0.876071\n",
      "loss: 0.943220\n",
      "loss: 0.956527\n",
      "loss: 0.893712\n",
      "loss: 0.807125\n",
      "loss: 0.953478\n",
      "loss: 0.741945\n",
      "loss: 0.880127\n",
      "loss: 0.903055\n",
      "loss: 0.846454\n",
      "loss: 0.835038\n",
      "loss: 0.874325\n",
      "loss: 0.860498\n",
      "loss: 0.801325\n",
      "loss: 0.657419\n",
      "loss: 0.947024\n",
      "loss: 0.840550\n",
      "loss: 0.724205\n",
      "loss: 0.757645\n",
      "loss: 0.881666\n",
      "loss: 1.068732\n",
      "loss: 0.796539\n",
      "loss: 0.754907\n",
      "loss: 0.765952\n",
      "loss: 0.799799\n",
      "loss: 0.872721\n",
      "loss: 0.702366\n",
      "loss: 0.794149\n",
      "loss: 0.930611\n",
      "loss: 0.871690\n",
      "loss: 0.715886\n",
      "loss: 0.721346\n",
      "loss: 0.810382\n",
      "loss: 0.870474\n",
      "loss: 0.775465\n",
      "loss: 0.795517\n",
      "loss: 0.777940\n",
      "loss: 0.692154\n",
      "loss: 0.787944\n",
      "loss: 0.677312\n",
      "loss: 0.928166\n",
      "loss: 0.793073\n",
      "loss: 0.939914\n",
      "loss: 0.894497\n",
      "loss: 0.741153\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.487619 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.920316\n",
      "loss: 0.768200\n",
      "loss: 0.898556\n",
      "loss: 0.965213\n",
      "loss: 0.727440\n",
      "loss: 0.810851\n",
      "loss: 0.820813\n",
      "loss: 0.798286\n",
      "loss: 0.741674\n",
      "loss: 0.802593\n",
      "loss: 0.841329\n",
      "loss: 0.784603\n",
      "loss: 0.909617\n",
      "loss: 0.656866\n",
      "loss: 0.950034\n",
      "loss: 0.749286\n",
      "loss: 0.801250\n",
      "loss: 0.748265\n",
      "loss: 0.908251\n",
      "loss: 0.761174\n",
      "loss: 0.836655\n",
      "loss: 0.804403\n",
      "loss: 0.863954\n",
      "loss: 0.877845\n",
      "loss: 0.810169\n",
      "loss: 0.780303\n",
      "loss: 0.787852\n",
      "loss: 0.704280\n",
      "loss: 0.770511\n",
      "loss: 0.704978\n",
      "loss: 0.697264\n",
      "loss: 0.659803\n",
      "loss: 0.755429\n",
      "loss: 0.765693\n",
      "loss: 0.812032\n",
      "loss: 0.623092\n",
      "loss: 0.833577\n",
      "loss: 0.714613\n",
      "loss: 0.792968\n",
      "loss: 0.793969\n",
      "loss: 0.616052\n",
      "loss: 0.862930\n",
      "loss: 0.679029\n",
      "loss: 0.780388\n",
      "loss: 0.743445\n",
      "loss: 0.853995\n",
      "loss: 0.812070\n",
      "loss: 0.906172\n",
      "loss: 0.688862\n",
      "loss: 0.817642\n",
      "loss: 0.746980\n",
      "loss: 0.673406\n",
      "loss: 0.672424\n",
      "loss: 0.791710\n",
      "loss: 0.877575\n",
      "loss: 0.769246\n",
      "loss: 0.706230\n",
      "loss: 0.784760\n",
      "loss: 0.749780\n",
      "loss: 0.711262\n",
      "loss: 0.774889\n",
      "loss: 0.598871\n",
      "loss: 0.768396\n",
      "loss: 0.715549\n",
      "loss: 0.695087\n",
      "loss: 0.819311\n",
      "loss: 0.665536\n",
      "loss: 0.661304\n",
      "loss: 0.774021\n",
      "loss: 0.643058\n",
      "loss: 0.644996\n",
      "loss: 0.690799\n",
      "loss: 0.825294\n",
      "loss: 0.716157\n",
      "loss: 0.803554\n",
      "loss: 0.632504\n",
      "loss: 0.798714\n",
      "loss: 0.795523\n",
      "loss: 0.814889\n",
      "loss: 0.768911\n",
      "loss: 0.753050\n",
      "loss: 0.707453\n",
      "loss: 0.742273\n",
      "loss: 1.014303\n",
      "loss: 0.662396\n",
      "loss: 0.706306\n",
      "loss: 0.792628\n",
      "loss: 0.752857\n",
      "loss: 0.736785\n",
      "loss: 0.720581\n",
      "loss: 0.743480\n",
      "loss: 0.803582\n",
      "loss: 0.718310\n",
      "loss: 0.767261\n",
      "loss: 0.719686\n",
      "loss: 0.744388\n",
      "loss: 0.786274\n",
      "loss: 0.775359\n",
      "loss: 0.865007\n",
      "loss: 0.841089\n",
      "loss: 0.656263\n",
      "loss: 0.628268\n",
      "loss: 0.599420\n",
      "loss: 0.587445\n",
      "loss: 0.641235\n",
      "loss: 0.812212\n",
      "loss: 0.779347\n",
      "loss: 0.617406\n",
      "loss: 0.817396\n",
      "loss: 0.734158\n",
      "loss: 0.806782\n",
      "loss: 0.803083\n",
      "loss: 0.933426\n",
      "loss: 0.696772\n",
      "loss: 0.781393\n",
      "loss: 0.808971\n",
      "loss: 0.814183\n",
      "loss: 0.698484\n",
      "loss: 0.811632\n",
      "loss: 0.678006\n",
      "loss: 0.767834\n",
      "loss: 0.703351\n",
      "loss: 0.731326\n",
      "loss: 0.796479\n",
      "loss: 0.712874\n",
      "loss: 0.672298\n",
      "loss: 0.687721\n",
      "loss: 0.759990\n",
      "loss: 0.705527\n",
      "loss: 0.704753\n",
      "loss: 0.828598\n",
      "loss: 0.748673\n",
      "loss: 0.691541\n",
      "loss: 0.797339\n",
      "loss: 0.820031\n",
      "loss: 0.707097\n",
      "loss: 0.733841\n",
      "loss: 0.588953\n",
      "loss: 0.708806\n",
      "loss: 0.864058\n",
      "loss: 0.708614\n",
      "loss: 0.642722\n",
      "loss: 0.721518\n",
      "loss: 0.821796\n",
      "loss: 0.616037\n",
      "loss: 0.751313\n",
      "loss: 0.638493\n",
      "loss: 0.725766\n",
      "loss: 0.695003\n",
      "loss: 0.830309\n",
      "loss: 0.810888\n",
      "loss: 0.688640\n",
      "loss: 0.797507\n",
      "loss: 0.681477\n",
      "loss: 0.815470\n",
      "loss: 0.743468\n",
      "loss: 0.602296\n",
      "loss: 0.755353\n",
      "loss: 0.919583\n",
      "loss: 0.750582\n",
      "loss: 0.690034\n",
      "loss: 0.693239\n",
      "loss: 0.631929\n",
      "loss: 0.861367\n",
      "loss: 0.870363\n",
      "loss: 0.728312\n",
      "loss: 0.819852\n",
      "loss: 0.684596\n",
      "loss: 0.775072\n",
      "loss: 0.885977\n",
      "loss: 0.772218\n",
      "loss: 0.888600\n",
      "loss: 0.586283\n",
      "loss: 0.743738\n",
      "loss: 0.770959\n",
      "loss: 0.833957\n",
      "loss: 0.618770\n",
      "loss: 0.778722\n",
      "loss: 0.824629\n",
      "loss: 0.596794\n",
      "loss: 0.740001\n",
      "loss: 0.683845\n",
      "loss: 0.650159\n",
      "loss: 0.617570\n",
      "loss: 0.764307\n",
      "loss: 0.738159\n",
      "loss: 0.714341\n",
      "loss: 0.742340\n",
      "loss: 0.796135\n",
      "loss: 0.691877\n",
      "loss: 0.738384\n",
      "loss: 0.955095\n",
      "loss: 0.896763\n",
      "loss: 0.663100\n",
      "loss: 0.763427\n",
      "loss: 0.727685\n",
      "loss: 0.710611\n",
      "loss: 0.712747\n",
      "loss: 0.635843\n",
      "loss: 0.718726\n",
      "loss: 0.710191\n",
      "loss: 0.726231\n",
      "loss: 0.716925\n",
      "loss: 0.583976\n",
      "loss: 0.627774\n",
      "loss: 0.555272\n",
      "loss: 0.708589\n",
      "loss: 0.648497\n",
      "loss: 0.689976\n",
      "loss: 0.780364\n",
      "loss: 0.747898\n",
      "loss: 0.730352\n",
      "loss: 0.663738\n",
      "loss: 0.717149\n",
      "loss: 0.676581\n",
      "loss: 0.614234\n",
      "loss: 0.655859\n",
      "loss: 0.717207\n",
      "loss: 0.978683\n",
      "loss: 0.686126\n",
      "loss: 0.603587\n",
      "loss: 0.687034\n",
      "loss: 0.726496\n",
      "loss: 0.759806\n",
      "loss: 0.784161\n",
      "loss: 0.658258\n",
      "loss: 0.774390\n",
      "loss: 0.743768\n",
      "loss: 0.794222\n",
      "loss: 0.815210\n",
      "loss: 0.787405\n",
      "loss: 0.652202\n",
      "loss: 0.711347\n",
      "loss: 0.683499\n",
      "loss: 0.856699\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.463428 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.670995\n",
      "loss: 0.930456\n",
      "loss: 0.674914\n",
      "loss: 0.723662\n",
      "loss: 0.635853\n",
      "loss: 0.658669\n",
      "loss: 0.857557\n",
      "loss: 0.728001\n",
      "loss: 0.764999\n",
      "loss: 0.878393\n",
      "loss: 0.644252\n",
      "loss: 0.791963\n",
      "loss: 0.774690\n",
      "loss: 0.692986\n",
      "loss: 0.688854\n",
      "loss: 0.833559\n",
      "loss: 0.675175\n",
      "loss: 0.768695\n",
      "loss: 0.627157\n",
      "loss: 0.709323\n",
      "loss: 0.662540\n",
      "loss: 0.793859\n",
      "loss: 0.749672\n",
      "loss: 0.794623\n",
      "loss: 0.996012\n",
      "loss: 0.644350\n",
      "loss: 0.711254\n",
      "loss: 0.758604\n",
      "loss: 0.594902\n",
      "loss: 0.632968\n",
      "loss: 0.689385\n",
      "loss: 0.771336\n",
      "loss: 0.544209\n",
      "loss: 0.655601\n",
      "loss: 0.908904\n",
      "loss: 0.715058\n",
      "loss: 0.596026\n",
      "loss: 0.663647\n",
      "loss: 0.750937\n",
      "loss: 0.744214\n",
      "loss: 0.639293\n",
      "loss: 0.630166\n",
      "loss: 0.770315\n",
      "loss: 0.734779\n",
      "loss: 0.607762\n",
      "loss: 0.740707\n",
      "loss: 0.706064\n",
      "loss: 0.734436\n",
      "loss: 0.637569\n",
      "loss: 0.729641\n",
      "loss: 0.743051\n",
      "loss: 0.737074\n",
      "loss: 0.973872\n",
      "loss: 0.753979\n",
      "loss: 0.588851\n",
      "loss: 0.714548\n",
      "loss: 0.796993\n",
      "loss: 0.814671\n",
      "loss: 0.589146\n",
      "loss: 0.801985\n",
      "loss: 0.949197\n",
      "loss: 0.616889\n",
      "loss: 0.854157\n",
      "loss: 0.802353\n",
      "loss: 0.564529\n",
      "loss: 0.612484\n",
      "loss: 0.631587\n",
      "loss: 0.768534\n",
      "loss: 0.666409\n",
      "loss: 0.762228\n",
      "loss: 0.726668\n",
      "loss: 0.766136\n",
      "loss: 0.848618\n",
      "loss: 0.629555\n",
      "loss: 0.743877\n",
      "loss: 0.646310\n",
      "loss: 0.643729\n",
      "loss: 0.756943\n",
      "loss: 0.774653\n",
      "loss: 0.592888\n",
      "loss: 0.691984\n",
      "loss: 0.703257\n",
      "loss: 0.791008\n",
      "loss: 0.719842\n",
      "loss: 0.836058\n",
      "loss: 0.785033\n",
      "loss: 0.686615\n",
      "loss: 0.680207\n",
      "loss: 0.503011\n",
      "loss: 0.717118\n",
      "loss: 0.656554\n",
      "loss: 0.824921\n",
      "loss: 0.766946\n",
      "loss: 0.713561\n",
      "loss: 0.750222\n",
      "loss: 0.643346\n",
      "loss: 0.580237\n",
      "loss: 0.769537\n",
      "loss: 0.802343\n",
      "loss: 0.605370\n",
      "loss: 0.637603\n",
      "loss: 0.775022\n",
      "loss: 0.731128\n",
      "loss: 0.747548\n",
      "loss: 0.741603\n",
      "loss: 0.692697\n",
      "loss: 0.883066\n",
      "loss: 0.813752\n",
      "loss: 0.761740\n",
      "loss: 0.811986\n",
      "loss: 0.887171\n",
      "loss: 0.624743\n",
      "loss: 0.764716\n",
      "loss: 0.703090\n",
      "loss: 0.742363\n",
      "loss: 0.571184\n",
      "loss: 0.682780\n",
      "loss: 0.683771\n",
      "loss: 0.757104\n",
      "loss: 0.666202\n",
      "loss: 0.802189\n",
      "loss: 0.769467\n",
      "loss: 0.782114\n",
      "loss: 0.742212\n",
      "loss: 0.732417\n",
      "loss: 0.672815\n",
      "loss: 0.742689\n",
      "loss: 0.778207\n",
      "loss: 0.595463\n",
      "loss: 0.945891\n",
      "loss: 0.873113\n",
      "loss: 0.780729\n",
      "loss: 0.926680\n",
      "loss: 0.903162\n",
      "loss: 0.732892\n",
      "loss: 0.663881\n",
      "loss: 0.757449\n",
      "loss: 0.750659\n",
      "loss: 0.657693\n",
      "loss: 0.937227\n",
      "loss: 0.674318\n",
      "loss: 0.676556\n",
      "loss: 0.775646\n",
      "loss: 0.890087\n",
      "loss: 0.684699\n",
      "loss: 0.920685\n",
      "loss: 0.862425\n",
      "loss: 0.712042\n",
      "loss: 0.838015\n",
      "loss: 1.003540\n",
      "loss: 0.611205\n",
      "loss: 0.638456\n",
      "loss: 0.728528\n",
      "loss: 0.813926\n",
      "loss: 0.909884\n",
      "loss: 0.818387\n",
      "loss: 0.805977\n",
      "loss: 0.713008\n",
      "loss: 0.699835\n",
      "loss: 0.809113\n",
      "loss: 0.573617\n",
      "loss: 0.718600\n",
      "loss: 1.079123\n",
      "loss: 0.663807\n",
      "loss: 0.663720\n",
      "loss: 0.654155\n",
      "loss: 0.788445\n",
      "loss: 0.885320\n",
      "loss: 0.668611\n",
      "loss: 0.754846\n",
      "loss: 0.715617\n",
      "loss: 0.863512\n",
      "loss: 0.688866\n",
      "loss: 0.801532\n",
      "loss: 0.699134\n",
      "loss: 0.560699\n",
      "loss: 0.829726\n",
      "loss: 0.801486\n",
      "loss: 0.782042\n",
      "loss: 0.758118\n",
      "loss: 0.858783\n",
      "loss: 0.859163\n",
      "loss: 0.759243\n",
      "loss: 0.801225\n",
      "loss: 0.744533\n",
      "loss: 0.812118\n",
      "loss: 0.788490\n",
      "loss: 0.751413\n",
      "loss: 0.884644\n",
      "loss: 0.786968\n",
      "loss: 0.853682\n",
      "loss: 1.115169\n",
      "loss: 0.678299\n",
      "loss: 0.928292\n",
      "loss: 0.745507\n",
      "loss: 0.909910\n",
      "loss: 0.804873\n",
      "loss: 0.806325\n",
      "loss: 0.670435\n",
      "loss: 0.734529\n",
      "loss: 0.825055\n",
      "loss: 0.869312\n",
      "loss: 0.780085\n",
      "loss: 0.767901\n",
      "loss: 0.813023\n",
      "loss: 0.764218\n",
      "loss: 0.816416\n",
      "loss: 0.626043\n",
      "loss: 0.813240\n",
      "loss: 0.742181\n",
      "loss: 0.682553\n",
      "loss: 0.823646\n",
      "loss: 0.705340\n",
      "loss: 0.825901\n",
      "loss: 0.645713\n",
      "loss: 0.678383\n",
      "loss: 0.655763\n",
      "loss: 0.849134\n",
      "loss: 0.777973\n",
      "loss: 0.761497\n",
      "loss: 0.952670\n",
      "loss: 0.724202\n",
      "loss: 0.651750\n",
      "loss: 0.781597\n",
      "loss: 0.796246\n",
      "loss: 0.667288\n",
      "loss: 0.978794\n",
      "loss: 0.717465\n",
      "loss: 0.834134\n",
      "loss: 0.893457\n",
      "loss: 0.813484\n",
      "loss: 0.716564\n",
      "loss: 0.817450\n",
      "loss: 0.733869\n",
      "loss: 0.681818\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.455933 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.878723\n",
      "loss: 0.872697\n",
      "loss: 0.669648\n",
      "loss: 0.731627\n",
      "loss: 0.754975\n",
      "loss: 0.767788\n",
      "loss: 0.705943\n",
      "loss: 0.994590\n",
      "loss: 0.753473\n",
      "loss: 0.735228\n",
      "loss: 0.863560\n",
      "loss: 0.963065\n",
      "loss: 0.896503\n",
      "loss: 0.765924\n",
      "loss: 0.946243\n",
      "loss: 0.580555\n",
      "loss: 0.745533\n",
      "loss: 0.750179\n",
      "loss: 0.746326\n",
      "loss: 0.725328\n",
      "loss: 0.746835\n",
      "loss: 1.044049\n",
      "loss: 0.726288\n",
      "loss: 0.758025\n",
      "loss: 0.776856\n",
      "loss: 0.739016\n",
      "loss: 0.679760\n",
      "loss: 0.761725\n",
      "loss: 0.632856\n",
      "loss: 0.724020\n",
      "loss: 0.917686\n",
      "loss: 0.602133\n",
      "loss: 0.759862\n",
      "loss: 0.859618\n",
      "loss: 0.731684\n",
      "loss: 0.893104\n",
      "loss: 0.756282\n",
      "loss: 0.657946\n",
      "loss: 0.721560\n",
      "loss: 0.690716\n",
      "loss: 0.674139\n",
      "loss: 0.609326\n",
      "loss: 0.657627\n",
      "loss: 0.751953\n",
      "loss: 0.832660\n",
      "loss: 0.734461\n",
      "loss: 0.927289\n",
      "loss: 0.574318\n",
      "loss: 0.594777\n",
      "loss: 0.695159\n",
      "loss: 0.746964\n",
      "loss: 0.684486\n",
      "loss: 0.689370\n",
      "loss: 0.645126\n",
      "loss: 0.570905\n",
      "loss: 0.781004\n",
      "loss: 0.741344\n",
      "loss: 0.781434\n",
      "loss: 0.741208\n",
      "loss: 0.910067\n",
      "loss: 0.776164\n",
      "loss: 0.875251\n",
      "loss: 0.812867\n",
      "loss: 0.737052\n",
      "loss: 0.760770\n",
      "loss: 0.878793\n",
      "loss: 0.669488\n",
      "loss: 0.725891\n",
      "loss: 0.755438\n",
      "loss: 0.892272\n",
      "loss: 0.716193\n",
      "loss: 0.534614\n",
      "loss: 0.668450\n",
      "loss: 0.905125\n",
      "loss: 0.612495\n",
      "loss: 0.573144\n",
      "loss: 0.877894\n",
      "loss: 0.640816\n",
      "loss: 0.658188\n",
      "loss: 0.789402\n",
      "loss: 0.798275\n",
      "loss: 0.705907\n",
      "loss: 0.731044\n",
      "loss: 0.739328\n",
      "loss: 0.669499\n",
      "loss: 0.680809\n",
      "loss: 0.834202\n",
      "loss: 0.719924\n",
      "loss: 0.671241\n",
      "loss: 0.639786\n",
      "loss: 0.649409\n",
      "loss: 0.774284\n",
      "loss: 0.970502\n",
      "loss: 0.746629\n",
      "loss: 0.737108\n",
      "loss: 0.774186\n",
      "loss: 0.737025\n",
      "loss: 0.651220\n",
      "loss: 0.870540\n",
      "loss: 0.522781\n",
      "loss: 0.705787\n",
      "loss: 0.877074\n",
      "loss: 0.756474\n",
      "loss: 0.700859\n",
      "loss: 0.726909\n",
      "loss: 0.802129\n",
      "loss: 0.634483\n",
      "loss: 0.924441\n",
      "loss: 0.624071\n",
      "loss: 0.573054\n",
      "loss: 0.811166\n",
      "loss: 0.796097\n",
      "loss: 0.580708\n",
      "loss: 0.804235\n",
      "loss: 0.783669\n",
      "loss: 0.655361\n",
      "loss: 0.702117\n",
      "loss: 0.794171\n",
      "loss: 0.813926\n",
      "loss: 0.747812\n",
      "loss: 0.641679\n",
      "loss: 0.709468\n",
      "loss: 0.830717\n",
      "loss: 0.673149\n",
      "loss: 0.739154\n",
      "loss: 0.805737\n",
      "loss: 0.889766\n",
      "loss: 0.783112\n",
      "loss: 0.846659\n",
      "loss: 0.852823\n",
      "loss: 0.651664\n",
      "loss: 0.775572\n",
      "loss: 0.916283\n",
      "loss: 0.706589\n",
      "loss: 0.830383\n",
      "loss: 0.885600\n",
      "loss: 0.793493\n",
      "loss: 0.722955\n",
      "loss: 0.891753\n",
      "loss: 0.862756\n",
      "loss: 0.893953\n",
      "loss: 0.741512\n",
      "loss: 0.895115\n",
      "loss: 0.852087\n",
      "loss: 0.852074\n",
      "loss: 0.683664\n",
      "loss: 0.696587\n",
      "loss: 0.763847\n",
      "loss: 0.765219\n",
      "loss: 0.932735\n",
      "loss: 0.738075\n",
      "loss: 0.716644\n",
      "loss: 0.869568\n",
      "loss: 0.691915\n",
      "loss: 0.722847\n",
      "loss: 0.789513\n",
      "loss: 0.745134\n",
      "loss: 0.825069\n",
      "loss: 0.696295\n",
      "loss: 0.916182\n",
      "loss: 0.790940\n",
      "loss: 0.664588\n",
      "loss: 0.710858\n",
      "loss: 0.874445\n",
      "loss: 0.844430\n",
      "loss: 0.957953\n",
      "loss: 0.841126\n",
      "loss: 0.835775\n",
      "loss: 0.835691\n",
      "loss: 0.745598\n",
      "loss: 0.760499\n",
      "loss: 0.827381\n",
      "loss: 0.702716\n",
      "loss: 0.899933\n",
      "loss: 0.743522\n",
      "loss: 0.596315\n",
      "loss: 0.723172\n",
      "loss: 0.752792\n",
      "loss: 0.701295\n",
      "loss: 0.821974\n",
      "loss: 0.691378\n",
      "loss: 0.696684\n",
      "loss: 0.651411\n",
      "loss: 0.813617\n",
      "loss: 0.695711\n",
      "loss: 0.728604\n",
      "loss: 0.645129\n",
      "loss: 0.724922\n",
      "loss: 0.722638\n",
      "loss: 0.792351\n",
      "loss: 0.899338\n",
      "loss: 0.686188\n",
      "loss: 0.785651\n",
      "loss: 0.912674\n",
      "loss: 0.818069\n",
      "loss: 1.033917\n",
      "loss: 0.779949\n",
      "loss: 0.545303\n",
      "loss: 0.836985\n",
      "loss: 0.754403\n",
      "loss: 0.707328\n",
      "loss: 0.712816\n",
      "loss: 0.785155\n",
      "loss: 0.820605\n",
      "loss: 0.656941\n",
      "loss: 0.729209\n",
      "loss: 0.749483\n",
      "loss: 0.744367\n",
      "loss: 0.808860\n",
      "loss: 0.761367\n",
      "loss: 0.941298\n",
      "loss: 0.704048\n",
      "loss: 0.912483\n",
      "loss: 0.830470\n",
      "loss: 0.601139\n",
      "loss: 0.802899\n",
      "loss: 0.663737\n",
      "loss: 0.688475\n",
      "loss: 0.837928\n",
      "loss: 1.262944\n",
      "loss: 0.701860\n",
      "loss: 0.610196\n",
      "loss: 0.715986\n",
      "loss: 0.926250\n",
      "loss: 0.803950\n",
      "loss: 0.639440\n",
      "loss: 0.717851\n",
      "loss: 0.649103\n",
      "loss: 0.877298\n",
      "loss: 0.782396\n",
      "loss: 0.862108\n",
      "loss: 0.811080\n",
      "loss: 0.822847\n",
      "loss: 0.689771\n",
      "loss: 1.020322\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.455880 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_loop(es_model, dataloader, loss_fn, nb_model_samples = 30):\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # keep track of stats for each model sample\n",
    "        samples_loss = []\n",
    "        correct = 0\n",
    "        for model in es_model.samples(nb_model_samples):\n",
    "            # Forward pass\n",
    "            pred = model(x)\n",
    "            samples_loss.append(loss_fn(pred, y))\n",
    "            correct += (pred.argmax(1) == y).sum().item()\n",
    "        samples_loss = torch.stack(samples_loss) \n",
    "        es_model.gradient_descent(samples_loss)\n",
    "        \n",
    "        print(f\"loss: {samples_loss.mean():>7f}\")\n",
    "        \n",
    "def test_loop(es_model, dataloader, loss_fn):\n",
    "    model = es_model.get_best_model()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def train():\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                             transform=Compose([\n",
    "                               ToTensor(),\n",
    "                               Normalize((0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "        batch_size=256, shuffle=True)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, download=True,\n",
    "                                    transform=Compose([\n",
    "                                    ToTensor(),\n",
    "                                    Normalize((0.1307,), (0.3081,))\n",
    "                                    ])),\n",
    "        batch_size=1000, shuffle=True)\n",
    "    with torch.no_grad(): # ES doesn't need gradient tracking\n",
    "        es_model = ESModel(Model=CNN, param_std=0.05, Optimizer=optim.Adam)\n",
    "        for epoch in range(1, 10):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "            # train the model\n",
    "            train_loop(es_model,train_dataloader, nn.CrossEntropyLoss(), nb_model_samples=1000)\n",
    "            test_loop(es_model, test_dataloader, nn.CrossEntropyLoss())\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
