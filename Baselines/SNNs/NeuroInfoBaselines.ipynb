{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrashubhAtri/heterogeneousSNNs/blob/main/Baselines/SNN/NeuroInfoBaselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8aaeDvtft-q"
      },
      "source": [
        "# ANN and Common Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5xBtmPhE60p"
      },
      "source": [
        "## CNN for MNIST\n",
        "- Completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ai5MoDfQaAvJ"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfrzcITHqDzd",
        "outputId": "610a06c7-dac1-458c-80ea-320260bbfd21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 484kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.89MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRD40VLo8Zaj",
        "outputId": "413bf109-b508-4290-efce-2dc418a87c22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.16729293107640927\n",
            "Epoch 2, Loss: 0.04710294775830369\n",
            "Epoch 3, Loss: 0.03250654283322708\n",
            "Epoch 4, Loss: 0.023459596810852492\n",
            "Epoch 5, Loss: 0.018297917085145214\n",
            "Training complete!\n",
            "Accuracy: 99.12%\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "2aV_Tx9D0WMr",
        "outputId": "9490e81f-584d-4154-c2c0-4ea4d3ef431d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "id = random.randint(0, len(testset))\n",
        "\n",
        "image, label = testset[id]\n",
        "image = image.unsqueeze(0)\n",
        "\n",
        "output = model(image)\n",
        "_, predicted = torch.max(output, 1)\n",
        "\n",
        "plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted.item()}, Actual: {label}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd4IXHzb80Lu"
      },
      "source": [
        "# SpikingJelly - SNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqxoFyEr83Tb"
      },
      "source": [
        "## MNIST Dataset\n",
        "- Accuracy at 95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJqAHs-n7PUS",
        "outputId": "14ba263c-4c4f-44fc-b642-44bd76e8bbd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting spikingjelly\n",
            "  Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (2.5.1+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (0.20.1+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from spikingjelly) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->spikingjelly)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->spikingjelly)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->spikingjelly)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->spikingjelly) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->spikingjelly) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->spikingjelly) (3.0.2)\n",
            "Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, spikingjelly\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 spikingjelly-0.0.0.0.14\n"
          ]
        }
      ],
      "source": [
        "! pip install spikingjelly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg-09_Gx9Czm"
      },
      "outputs": [],
      "source": [
        "import spikingjelly.activation_based as sj\n",
        "import spikingjelly.activation_based.neuron as neuron\n",
        "import spikingjelly.activation_based.functional as functional\n",
        "import spikingjelly.activation_based.surrogate as surrogate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gp8K594u9TqS",
        "outputId": "2ca7f663-1b33-49ee-8490-ddd8fbd43e0d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "def spike_latency_encoding(image, tau=50.0, threshold=0.2):\n",
        "    image = image.squeeze(0)\n",
        "    latencies = tau * torch.log(image / (image - threshold))\n",
        "    latencies[image < threshold] = float('inf')\n",
        "    return latencies\n",
        "\n",
        "sample_img, _ = trainset[0]\n",
        "spike_latencies = spike_latency_encoding(sample_img)\n",
        "\n",
        "plt.imshow(spike_latencies.numpy(), cmap='hot')\n",
        "plt.title(\"Spike Latency Encoding\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtemCq01_cR-",
        "outputId": "12e09953-7b9c-4a47-89dd-4e2fe4f77757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in trainloader:\n",
        "    print(images.shape)  # Should print (batch_size, 1, 28, 28)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2JRB5bGBrQH",
        "outputId": "e3f40564-ffc5-4e25-a692-70ca693fd9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in testloader:\n",
        "    print(images.shape)  # Should print (batch_size, 1, 28, 28)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDOhjeLl9Zi1"
      },
      "outputs": [],
      "source": [
        "class SNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input Layer\n",
        "        self.lif1 = neuron.LIFNode(surrogate_function=surrogate.Sigmoid())  # Correct usage\n",
        "        self.fc2 = nn.Linear(128, 10)  # Output Layer\n",
        "        self.lif2 = neuron.LIFNode(surrogate_function=surrogate.Sigmoid())  # Correct usage\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)  # Flatten input\n",
        "        x = self.lif1(self.fc1(x))\n",
        "        x = self.lif2(self.fc2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvE-ATl5_hBn",
        "outputId": "c7eb59a3-1072-4a6b-e9c3-ad426f6e41a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "model = SNN()\n",
        "sample_input = torch.randn(64, 1, 28, 28)  # Fake batch of MNIST images\n",
        "output = model(sample_input)\n",
        "print(output.shape)  # Should be (64, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmU7aavh9ght"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LRcVHrg9j2c",
        "outputId": "822adccd-c172-459f-a476-e47767d379cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.024949900821844735\n",
            "Epoch 2, Loss: 0.02366651953260104\n",
            "Epoch 3, Loss: 0.02349135568936666\n",
            "Epoch 4, Loss: 0.023378476770718894\n",
            "Epoch 5, Loss: 0.023301302979389826\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "time_steps = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Reset neuron states before processing a new batch\n",
        "        functional.reset_net(model)\n",
        "\n",
        "        images = images.view(images.shape[0], -1)\n",
        "\n",
        "        spike_inputs = torch.zeros((images.shape[0], time_steps, 784))\n",
        "        latencies = spike_latency_encoding(images)\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            spike_inputs[:, t, :] = (latencies.view(latencies.shape[0], -1) < (t + 1) * 5).float()\n",
        "\n",
        "        outputs = model(spike_inputs.mean(dim=1))\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_O3zV9d9pLW",
        "outputId": "67c72625-999d-42da-fe95-fdb22e1ea754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 94.05%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in torch.utils.data.DataLoader(testset, batch_size=64):\n",
        "        functional.reset_net(model)\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        spike_inputs = torch.zeros((images.shape[0], time_steps, 28 * 28))\n",
        "        latencies = spike_latency_encoding(images)\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            spike_inputs[:, t, :] = (latencies.view(latencies.shape[0], -1) < (t + 1) * 5).float()\n",
        "\n",
        "        outputs = model(spike_inputs.mean(dim=1))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0nt_dA-AjnQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4aky4ugEPoX"
      },
      "source": [
        "## Synthetic Smooth Random Manifold Spiking Data Set\n",
        "- Result coming\n",
        "- Accuracy way off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By6vAKNKtXcF",
        "outputId": "c511f0e9-bf16-4d2c-fd5e-5fbcdf8e1cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: snntorch\n",
            "Successfully installed snntorch-0.9.4\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LVI68s39KCg",
        "outputId": "1a1f135d-69c0-4411-a418-cfb7bf189f40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 2.0775, Spikes: 12590\n",
            "Epoch [2/10], Loss: 1.6645, Spikes: 6306\n",
            "Epoch [3/10], Loss: 1.6045, Spikes: 3947\n",
            "Epoch [4/10], Loss: 1.6003, Spikes: 3491\n",
            "Epoch [5/10], Loss: 1.5999, Spikes: 3369\n",
            "Epoch [6/10], Loss: 1.5995, Spikes: 3294\n",
            "Epoch [7/10], Loss: 1.5988, Spikes: 3272\n",
            "Epoch [8/10], Loss: 1.5988, Spikes: 3252\n",
            "Epoch [9/10], Loss: 1.5989, Spikes: 3231\n",
            "Epoch [10/10], Loss: 1.5987, Spikes: 3221\n",
            "Test Accuracy: 53.75%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import pandas as pd\n",
        "\n",
        "# Load Dataset from CSV\n",
        "file_path = 'spiking_time_dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Assume the first column is labels and the rest are spike times\n",
        "labels = torch.tensor(data.iloc[:, 0].values, dtype=torch.long)\n",
        "spike_times = torch.tensor(data.iloc[:, 1:].values, dtype=torch.float32)\n",
        "\n",
        "# Convert spike times to spike trains\n",
        "def convert_to_spike_trains(spike_times, num_time_steps=50):\n",
        "    num_samples, num_neurons = spike_times.shape\n",
        "    spike_trains = torch.zeros((num_samples, num_neurons, num_time_steps))\n",
        "    for t in range(num_time_steps):\n",
        "        spike_trains[:, :, t] = torch.exp(-((spike_times - t) ** 2) / 2).float()\n",
        "    return spike_trains\n",
        "\n",
        "spike_trains = convert_to_spike_trains(spike_times)\n",
        "\n",
        "# Split into training and testing\n",
        "train_size = int(0.8 * len(spike_trains))\n",
        "test_size = len(spike_trains) - train_size\n",
        "train_spike_trains, test_spike_trains = torch.utils.data.random_split(spike_trains, [train_size, test_size])\n",
        "train_labels, test_labels = torch.utils.data.random_split(labels, [train_size, test_size])\n",
        "\n",
        "# Define Improved SNN Model\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, num_inputs=spike_times.shape[1], num_hidden=100, num_outputs=10, beta=0.85):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.bn1 = nn.BatchNorm1d(num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta, learn_beta=True, threshold=0.5, reset_mechanism=\"subtract\",\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=5))\n",
        "\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        # self.bn2 = nn.BatchNorm1d(num_hidden)\n",
        "        self.lif2 = snn.Leaky(beta=beta, learn_beta=True, threshold=0.5, reset_mechanism=\"subtract\",\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=5))\n",
        "\n",
        "        # self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
        "        # self.lif3 = snn.Leaky(beta=beta, learn_beta=True, threshold=0.7, reset_mechanism=\"subtract\",\n",
        "                              # spike_grad=surrogate.fast_sigmoid(slope=5))\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)  # Prevent overfitting\n",
        "\n",
        "        # Xavier Uniform Initialization for Stability\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_neurons, time_steps = x.shape\n",
        "        x = x.permute(2, 0, 1)  # (time, batch, neurons)\n",
        "\n",
        "        # mem1, mem2, mem3 = [torch.zeros(batch_size, layer.out_features, device=x.device)\n",
        "                            #  for layer in [self.fc1, self.fc2, self.fc3]]\n",
        "        mem1, mem2 = [torch.zeros(batch_size, layer.out_features, device=x.device)\n",
        "                             for layer in [self.fc1, self.fc2]]\n",
        "        spk2_rec = []\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            spk1, mem1 = self.lif1(self.bn1(self.fc1(x[t])), mem1)\n",
        "            # spk2, mem2 = self.lif2(self.bn2(self.fc2(spk1) + spk1), mem2)  # Residual Connection\n",
        "            # spk2 = self.dropout(spk2)\n",
        "            # spk3, mem3 = self.lif3(self.fc3(spk2), mem3)\n",
        "            # spk3_rec.append(spk3)\n",
        "            spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
        "            spk2_rec.append(spk2)\n",
        "\n",
        "        # spk3_rec = torch.stack(spk3_rec, dim=0).mean(0)  # Max-over-time readout\n",
        "        spk2_rec = torch.stack(spk2_rec, dim=0).mean(0)  # Max-over-time readout\n",
        "        return spk2_rec\n",
        "\n",
        "# Instantiate Model\n",
        "model = SNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "\n",
        "# Data Loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(train_spike_trains, train_labels)), batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(test_spike_trains, test_labels)), batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_spikes = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient Clipping\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        total_spikes += (outputs > 0).sum().item()  # Count active neurons\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    scheduler.step()  # Adjust learning rate dynamically\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Spikes: {total_spikes}\")\n",
        "\n",
        "# Testing Loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hbVbrlUJfbW",
        "outputId": "3b9f66f5-8d58-456d-ea73-86504f7f6ade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([74.8825, 45.3203, 56.8354, 67.3241, 35.1018, 18.4770,  9.8592, 90.2051,\n",
              "         1.6925, 94.1393, 54.4921, 62.1268, 95.6491, 37.7465, 81.6426, 12.3235,\n",
              "         0.4666, 98.9531, 15.1895, 23.2405, 89.4766, 13.0404, 58.8911, 48.2181,\n",
              "        77.3262, 50.1658, 61.8191, 64.3078, 40.2995, 63.4450])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spike_times[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9zVbkRR9WG1"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQeD0vlxEWVj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def generate_manifold_data(num_samples=1000, num_neurons=100, alpha=3, D=1):\n",
        "    \"\"\"\n",
        "    Generates smooth random manifold spiking data.\n",
        "\n",
        "    :param num_samples: Number of data points\n",
        "    :param num_neurons: Number of neurons (input dimension)\n",
        "    :param alpha: Smoothness parameter of the manifold\n",
        "    :param D: Intrinsic dimensionality of the manifold\n",
        "    :return: Spike times tensor\n",
        "    \"\"\"\n",
        "    X = np.random.rand(num_samples, D).squeeze()  # Ensure correct shape (1000,)\n",
        "    spike_times = np.zeros((num_samples, num_neurons))\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        theta = np.random.rand()  # Random offset per neuron\n",
        "        spike_times[:, i] = np.sin(2 * np.pi * (X + theta)).squeeze() * alpha\n",
        "\n",
        "    spike_times = np.clip(spike_times, 0, 50)  # Clip to max simulation time (50ms)\n",
        "    return torch.tensor(spike_times, dtype=torch.float32)\n",
        "\n",
        "# Generate training and testing data\n",
        "num_samples = 1000\n",
        "num_neurons = 100\n",
        "train_spikes = generate_manifold_data(num_samples=num_samples, num_neurons=num_neurons)\n",
        "test_spikes = generate_manifold_data(num_samples=200, num_neurons=num_neurons)\n",
        "train_labels = torch.randint(0, 10, (num_samples,))  # 10-class classification\n",
        "test_labels = torch.randint(0, 10, (200,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXY_QXk5pNE8"
      },
      "outputs": [],
      "source": [
        "def convert_to_spike_trains(spike_times, num_time_steps=50):\n",
        "    \"\"\"\n",
        "    Converts spike timing data to binary spike trains.\n",
        "\n",
        "    :param spike_times: Tensor of spike timings\n",
        "    :param num_time_steps: Number of time steps to simulate\n",
        "    :return: Binary spike train tensor\n",
        "    \"\"\"\n",
        "    num_samples, num_neurons = spike_times.shape\n",
        "    spike_trains = torch.zeros((num_samples, num_neurons, num_time_steps))\n",
        "\n",
        "    for t in range(num_time_steps):\n",
        "        spike_trains[:, :, t] = (spike_times == t).float()\n",
        "\n",
        "    return spike_trains\n",
        "\n",
        "# Convert data\n",
        "num_time_steps = 50\n",
        "train_spike_trains = convert_to_spike_trains(train_spikes, num_time_steps)\n",
        "test_spike_trains = convert_to_spike_trains(test_spikes, num_time_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q83M9F_6pRTg"
      },
      "outputs": [],
      "source": [
        "class SNN(nn.Module):\n",
        "    def __init__(self, num_inputs=100, num_hidden=256, num_outputs=10):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = neuron.LIFNode(surrogate_function=surrogate.Sigmoid())\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = neuron.LIFNode(surrogate_function=surrogate.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_neurons, time_steps = x.shape\n",
        "        x = x.permute(2, 0, 1)  # (time, batch, neurons)\n",
        "        mem1 = torch.zeros(batch_size, 256, device=x.device)\n",
        "        mem2 = torch.zeros(batch_size, 10, device=x.device)\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            mem1 = self.lif1(self.fc1(x[t]))\n",
        "            mem2 = self.lif2(self.fc2(mem1))\n",
        "\n",
        "        return mem2  # Output is the final membrane potential\n",
        "\n",
        "# Instantiate Model\n",
        "model = SNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z2qZLD3pT-L"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdw5cHSgpWPK",
        "outputId": "6bbc642e-5c8a-49da-f122-7e4287065c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 2.3025851249694824\n",
            "Epoch 2, Loss: 2.3025851249694824\n",
            "Epoch 3, Loss: 2.3025851249694824\n",
            "Epoch 4, Loss: 2.3025851249694824\n",
            "Epoch 5, Loss: 2.3025851249694824\n",
            "Epoch 6, Loss: 2.3025851249694824\n",
            "Epoch 7, Loss: 2.3025851249694824\n",
            "Epoch 8, Loss: 2.3025851249694824\n",
            "Epoch 9, Loss: 2.3025851249694824\n",
            "Epoch 10, Loss: 2.3025851249694824\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(train_spike_trains, train_labels)), batch_size=batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(test_spike_trains, test_labels)), batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        functional.reset_net(model)  # Reset neuron states\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbEBDvghpajK",
        "outputId": "820b58a9-28d6-4009-bbcb-6af6bb3db476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 10.50%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        functional.reset_net(model)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srre9muguLvH",
        "outputId": "b8101c05-f6fc-4ff4-8f97-4137a6b76e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.11/dist-packages (0.9.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FESRQvQWePnf",
        "outputId": "08cfb312-3998-4e0a-a576-d71fc3ef6c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 2.3026\n",
            "Epoch [2/50], Loss: 2.3023\n",
            "Epoch [3/50], Loss: 2.3015\n",
            "Epoch [4/50], Loss: 2.2994\n",
            "Epoch [5/50], Loss: 2.2984\n",
            "Epoch [6/50], Loss: 2.2977\n",
            "Epoch [7/50], Loss: 2.2976\n",
            "Epoch [8/50], Loss: 2.2969\n",
            "Epoch [9/50], Loss: 2.2975\n",
            "Epoch [10/50], Loss: 2.2972\n",
            "Epoch [11/50], Loss: 2.2976\n",
            "Epoch [12/50], Loss: 2.2962\n",
            "Epoch [13/50], Loss: 2.2962\n",
            "Epoch [14/50], Loss: 2.2963\n",
            "Epoch [15/50], Loss: 2.2952\n",
            "Epoch [16/50], Loss: 2.2956\n",
            "Epoch [17/50], Loss: 2.2957\n",
            "Epoch [18/50], Loss: 2.2952\n",
            "Epoch [19/50], Loss: 2.2959\n",
            "Epoch [20/50], Loss: 2.2947\n",
            "Epoch [21/50], Loss: 2.2960\n",
            "Epoch [22/50], Loss: 2.2962\n",
            "Epoch [23/50], Loss: 2.2945\n",
            "Epoch [24/50], Loss: 2.2943\n",
            "Epoch [25/50], Loss: 2.2955\n",
            "Epoch [26/50], Loss: 2.2947\n",
            "Epoch [27/50], Loss: 2.2937\n",
            "Epoch [28/50], Loss: 2.2949\n",
            "Epoch [29/50], Loss: 2.2950\n",
            "Epoch [30/50], Loss: 2.2941\n",
            "Epoch [31/50], Loss: 2.2946\n",
            "Epoch [32/50], Loss: 2.2940\n",
            "Epoch [33/50], Loss: 2.2939\n",
            "Epoch [34/50], Loss: 2.2938\n",
            "Epoch [35/50], Loss: 2.2935\n",
            "Epoch [36/50], Loss: 2.2931\n",
            "Epoch [37/50], Loss: 2.2928\n",
            "Epoch [38/50], Loss: 2.2938\n",
            "Epoch [39/50], Loss: 2.2913\n",
            "Epoch [40/50], Loss: 2.2929\n",
            "Epoch [41/50], Loss: 2.2918\n",
            "Epoch [42/50], Loss: 2.2926\n",
            "Epoch [43/50], Loss: 2.2918\n",
            "Epoch [44/50], Loss: 2.2910\n",
            "Epoch [45/50], Loss: 2.2899\n",
            "Epoch [46/50], Loss: 2.2895\n",
            "Epoch [47/50], Loss: 2.2908\n",
            "Epoch [48/50], Loss: 2.2900\n",
            "Epoch [49/50], Loss: 2.2899\n",
            "Epoch [50/50], Loss: 2.2888\n",
            "Test Accuracy: 10.00%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate, functional\n",
        "\n",
        "# Generate Manifold Data\n",
        "def generate_manifold_data(num_samples=1000, num_neurons=100, alpha=3, D=1):\n",
        "    X = np.random.rand(num_samples, D).squeeze()\n",
        "    spike_times = np.zeros((num_samples, num_neurons))\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        theta = np.random.rand()\n",
        "        spike_times[:, i] = np.sin(2 * np.pi * (X + theta)) * alpha\n",
        "\n",
        "    spike_times = np.clip(spike_times, 0, 50)\n",
        "    return torch.tensor(spike_times, dtype=torch.float32)\n",
        "\n",
        "# Improved Encoding: Probability-based spike generation\n",
        "def convert_to_spike_trains(spike_times, num_time_steps=50):\n",
        "    num_samples, num_neurons = spike_times.shape\n",
        "    spike_trains = torch.zeros((num_samples, num_neurons, num_time_steps))\n",
        "\n",
        "    for t in range(num_time_steps):\n",
        "        spike_trains[:, :, t] = torch.exp(-((spike_times - t) ** 2) / 2).float()\n",
        "\n",
        "    return spike_trains\n",
        "\n",
        "# Generate training and testing data\n",
        "num_samples = 1000\n",
        "num_neurons = 100\n",
        "train_spikes = generate_manifold_data(num_samples=num_samples, num_neurons=num_neurons)\n",
        "test_spikes = generate_manifold_data(num_samples=200, num_neurons=num_neurons)\n",
        "\n",
        "train_spike_trains = convert_to_spike_trains(train_spikes)\n",
        "test_spike_trains = convert_to_spike_trains(test_spikes)\n",
        "\n",
        "train_labels = torch.randint(0, 10, (num_samples,))\n",
        "test_labels = torch.randint(0, 10, (200,))\n",
        "\n",
        "# Define SNN Model\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, num_inputs=100, num_hidden=256, num_outputs=10):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(\n",
        "            beta=0.9,\n",
        "            learn_beta=True,\n",
        "            threshold=1.0,\n",
        "            spike_grad=surrogate.fast_sigmoid(slope=25)\n",
        "        )\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(\n",
        "            beta=0.9,\n",
        "            learn_beta=True,\n",
        "            threshold=1.0,\n",
        "            spike_grad=surrogate.fast_sigmoid(slope=25)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_neurons, time_steps = x.shape\n",
        "        x = x.permute(2, 0, 1)  # (time, batch, neurons)\n",
        "\n",
        "        # Initialize hidden states\n",
        "        mem1 = torch.zeros(batch_size, 256, device=x.device)\n",
        "        mem2 = torch.zeros(batch_size, 10, device=x.device)\n",
        "\n",
        "        spk1_rec = []\n",
        "        spk2_rec = []\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            # No in-place operations and proper state handling\n",
        "            spk1, mem1 = self.lif1(self.fc1(x[t]), mem1)\n",
        "            spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
        "\n",
        "            spk1_rec.append(spk1)\n",
        "            spk2_rec.append(spk2)\n",
        "\n",
        "        # Stack and compute the mean across time steps\n",
        "        spk2_rec = torch.stack(spk2_rec, dim=0).mean(0)\n",
        "\n",
        "        return spk2_rec\n",
        "\n",
        "# Instantiate Model\n",
        "model = SNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Data Loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(train_spike_trains, train_labels)), batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(test_spike_trains, test_labels)), batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "torch.autograd.set_detect_anomaly(True)  # Enable anomaly detection\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Reset neuron states at the start of each batch\n",
        "        spk1_rec.detach_()\n",
        "        spk2_rec.detach_()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation — Allow BPTT by setting retain_graph=True\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Testing Loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        # Reset neuron states at the start of each test batch\n",
        "        spk1_rec.detach_()\n",
        "        spk2_rec.detach_()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNTUF-0i268K",
        "outputId": "091b27f1-e6be-4f4b-fa7d-7bab1e0b7a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 2.3011\n",
            "Epoch [2/50], Loss: 2.2982\n",
            "Epoch [3/50], Loss: 2.2997\n",
            "Epoch [4/50], Loss: 2.2966\n",
            "Epoch [5/50], Loss: 2.2975\n",
            "Epoch [6/50], Loss: 2.2950\n",
            "Epoch [7/50], Loss: 2.2951\n",
            "Epoch [8/50], Loss: 2.2952\n",
            "Epoch [9/50], Loss: 2.2952\n",
            "Epoch [10/50], Loss: 2.2939\n",
            "Epoch [11/50], Loss: 2.2937\n",
            "Epoch [12/50], Loss: 2.2932\n",
            "Epoch [13/50], Loss: 2.2930\n",
            "Epoch [14/50], Loss: 2.2940\n",
            "Epoch [15/50], Loss: 2.2964\n",
            "Epoch [16/50], Loss: 2.2945\n",
            "Epoch [17/50], Loss: 2.2936\n",
            "Epoch [18/50], Loss: 2.2938\n",
            "Epoch [19/50], Loss: 2.2937\n",
            "Epoch [20/50], Loss: 2.2934\n",
            "Epoch [21/50], Loss: 2.2933\n",
            "Epoch [22/50], Loss: 2.2958\n",
            "Epoch [23/50], Loss: 2.2942\n",
            "Epoch [24/50], Loss: 2.2928\n",
            "Epoch [25/50], Loss: 2.2942\n",
            "Epoch [26/50], Loss: 2.2927\n",
            "Epoch [27/50], Loss: 2.2929\n",
            "Epoch [28/50], Loss: 2.2923\n",
            "Epoch [29/50], Loss: 2.2935\n",
            "Epoch [30/50], Loss: 2.2938\n",
            "Epoch [31/50], Loss: 2.2934\n",
            "Epoch [32/50], Loss: 2.2944\n",
            "Epoch [33/50], Loss: 2.2934\n",
            "Epoch [34/50], Loss: 2.2933\n",
            "Epoch [35/50], Loss: 2.2927\n",
            "Epoch [36/50], Loss: 2.2941\n",
            "Epoch [37/50], Loss: 2.2937\n",
            "Epoch [38/50], Loss: 2.2933\n",
            "Epoch [39/50], Loss: 2.2927\n",
            "Epoch [40/50], Loss: 2.2924\n",
            "Epoch [41/50], Loss: 2.2940\n",
            "Epoch [42/50], Loss: 2.2933\n",
            "Epoch [43/50], Loss: 2.2931\n",
            "Epoch [44/50], Loss: 2.2925\n",
            "Epoch [45/50], Loss: 2.2932\n",
            "Epoch [46/50], Loss: 2.2926\n",
            "Epoch [47/50], Loss: 2.2944\n",
            "Epoch [48/50], Loss: 2.2933\n",
            "Epoch [49/50], Loss: 2.2927\n",
            "Epoch [50/50], Loss: 2.2930\n",
            "Test Accuracy: 8.50%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "\n",
        "# Generate Manifold Data\n",
        "def generate_manifold_data(num_samples=1000, num_neurons=100, alpha=3, D=1):\n",
        "    X = np.random.rand(num_samples, D).squeeze()\n",
        "    spike_times = np.zeros((num_samples, num_neurons))\n",
        "    for i in range(num_neurons):\n",
        "        theta = np.random.rand()\n",
        "        spike_times[:, i] = np.sin(2 * np.pi * (X + theta)) * alpha\n",
        "    spike_times = np.clip(spike_times, 0, 50)\n",
        "    return torch.tensor(spike_times, dtype=torch.float32)\n",
        "\n",
        "# Improved Encoding: Probability-based spike generation\n",
        "def convert_to_spike_trains(spike_times, num_time_steps=50):\n",
        "    num_samples, num_neurons = spike_times.shape\n",
        "    spike_trains = torch.zeros((num_samples, num_neurons, num_time_steps))\n",
        "    for t in range(num_time_steps):\n",
        "        spike_trains[:, :, t] = torch.exp(-((spike_times - t) ** 2) / 2).float()\n",
        "    return spike_trains\n",
        "\n",
        "# Generate training and testing data\n",
        "num_samples = 1000\n",
        "num_neurons = 100\n",
        "train_spikes = generate_manifold_data(num_samples=num_samples, num_neurons=num_neurons)\n",
        "test_spikes = generate_manifold_data(num_samples=200, num_neurons=num_neurons)\n",
        "\n",
        "train_spike_trains = convert_to_spike_trains(train_spikes)\n",
        "test_spike_trains = convert_to_spike_trains(test_spikes)\n",
        "\n",
        "train_labels = torch.randint(0, 10, (num_samples,))\n",
        "test_labels = torch.randint(0, 10, (200,))\n",
        "\n",
        "# Define SNN Model with Optimized Surrogate Gradient\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, num_inputs=100, num_hidden=256, num_outputs=10, beta=0.9):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta, learn_beta=True, threshold=1.0,\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=10))\n",
        "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.lif2 = snn.Leaky(beta=beta, learn_beta=True, threshold=1.0,\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=10))\n",
        "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif3 = snn.Leaky(beta=beta, learn_beta=True, threshold=1.0,\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_neurons, time_steps = x.shape\n",
        "        x = x.permute(2, 0, 1)  # (time, batch, neurons)\n",
        "\n",
        "        mem1, mem2, mem3 = [torch.zeros(batch_size, layer.out_features, device=x.device)\n",
        "                             for layer in [self.fc1, self.fc2, self.fc3]]\n",
        "        spk3_rec = []\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            spk1, mem1 = self.lif1(self.fc1(x[t]), mem1)\n",
        "            spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
        "            spk3, mem3 = self.lif3(self.fc3(spk2), mem3)\n",
        "            spk3_rec.append(spk3)\n",
        "\n",
        "        spk3_rec = torch.stack(spk3_rec, dim=0).mean(0)  # Max-over-time readout\n",
        "        return spk3_rec\n",
        "\n",
        "# Instantiate Model\n",
        "model = SNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "# Data Loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(train_spike_trains, train_labels)), batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(test_spike_trains, test_labels)), batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Testing Loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rRJh9aLxuCXW",
        "outputId": "3e0b6099-ddcc-4550-ef9d-4d4299b38714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 2.3056\n",
            "Epoch [2/50], Loss: 2.2996\n",
            "Epoch [3/50], Loss: 2.2982\n",
            "Epoch [4/50], Loss: 2.2977\n",
            "Epoch [5/50], Loss: 2.2976\n",
            "Epoch [6/50], Loss: 2.2968\n",
            "Epoch [7/50], Loss: 2.2977\n",
            "Epoch [8/50], Loss: 2.2961\n",
            "Epoch [9/50], Loss: 2.2946\n",
            "Epoch [10/50], Loss: 2.2973\n",
            "Epoch [11/50], Loss: 2.2977\n",
            "Epoch [12/50], Loss: 2.2985\n",
            "Epoch [13/50], Loss: 2.2972\n",
            "Epoch [14/50], Loss: 2.2959\n",
            "Epoch [15/50], Loss: 2.2961\n",
            "Epoch [16/50], Loss: 2.2940\n",
            "Epoch [17/50], Loss: 2.2938\n",
            "Epoch [18/50], Loss: 2.2922\n",
            "Epoch [19/50], Loss: 2.2918\n",
            "Epoch [20/50], Loss: 2.2877\n",
            "Epoch [21/50], Loss: 2.2879\n",
            "Epoch [22/50], Loss: 2.2865\n",
            "Epoch [23/50], Loss: 2.2851\n",
            "Epoch [24/50], Loss: 2.2825\n",
            "Epoch [25/50], Loss: 2.2865\n",
            "Epoch [26/50], Loss: 2.2863\n",
            "Epoch [27/50], Loss: 2.2846\n",
            "Epoch [28/50], Loss: 2.2858\n",
            "Epoch [29/50], Loss: 2.2837\n",
            "Epoch [30/50], Loss: 2.2836\n",
            "Epoch [31/50], Loss: 2.2810\n",
            "Epoch [32/50], Loss: 2.2800\n",
            "Epoch [33/50], Loss: 2.2826\n",
            "Epoch [34/50], Loss: 2.2832\n",
            "Epoch [35/50], Loss: 2.2816\n",
            "Epoch [36/50], Loss: 2.2798\n",
            "Epoch [37/50], Loss: 2.2832\n",
            "Epoch [38/50], Loss: 2.2831\n",
            "Epoch [39/50], Loss: 2.2806\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-1cff8a3a30e9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-1cff8a3a30e9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mspk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Residual Connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mspk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mspk3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mspk3_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/snntorch/_neurons/leaky.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    218\u001b[0m             )  # batch_size\n\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mspk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_delay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/snntorch/_neurons/neurons.py\u001b[0m in \u001b[0;36mfire\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mmem_shift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mspk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspike_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# fallback to traceback.format_stack()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         return klass._extract_from_extended_frame_gen(\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mextended_frame_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookup_lines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             capture_locals=capture_locals)\n",
            "\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36m_extract_from_extended_frame_gen\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    427\u001b[0m                 end_lineno=end_lineno, colno=colno, end_colno=end_colno))\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# First call the original checkcache as intended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# to our compiled codes can be produced.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mcontinue\u001b[0m   \u001b[0;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "# Generate Manifold Data\n",
        "def generate_manifold_data(num_samples=1000, num_neurons=100, alpha=3, D=1):\n",
        "    X = np.random.rand(num_samples, D).squeeze()\n",
        "    spike_times = np.zeros((num_samples, num_neurons))\n",
        "    for i in range(num_neurons):\n",
        "        theta = np.random.rand()\n",
        "        spike_times[:, i] = np.sin(2 * np.pi * (X + theta)) * alpha\n",
        "    spike_times = np.clip(spike_times, 0, 50)\n",
        "    return torch.tensor(spike_times, dtype=torch.float32)\n",
        "\n",
        "# Improved Encoding: Probability-based spike generation\n",
        "def convert_to_spike_trains(spike_times, num_time_steps=50):\n",
        "    num_samples, num_neurons = spike_times.shape\n",
        "    spike_trains = torch.zeros((num_samples, num_neurons, num_time_steps))\n",
        "    for t in range(num_time_steps):\n",
        "        spike_trains[:, :, t] = torch.exp(-((spike_times - t) ** 2) / 2).float()\n",
        "    return spike_trains\n",
        "\n",
        "# Generate training and testing data\n",
        "num_samples = 1000\n",
        "num_neurons = 100\n",
        "train_spikes = generate_manifold_data(num_samples=num_samples, num_neurons=num_neurons)\n",
        "test_spikes = generate_manifold_data(num_samples=200, num_neurons=num_neurons)\n",
        "\n",
        "train_spike_trains = convert_to_spike_trains(train_spikes)\n",
        "test_spike_trains = convert_to_spike_trains(test_spikes)\n",
        "\n",
        "train_labels = torch.randint(0, 10, (num_samples,))\n",
        "test_labels = torch.randint(0, 10, (200,))\n",
        "\n",
        "# Define Improved SNN Model\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, num_inputs=100, num_hidden=256, num_outputs=10, beta=0.9):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.bn1 = nn.BatchNorm1d(num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta, learn_beta=True, threshold=0.9,\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=25))\n",
        "\n",
        "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.bn2 = nn.BatchNorm1d(num_hidden)\n",
        "        self.lif2 = snn.Leaky(beta=beta, learn_beta=True, threshold=0.9,\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=25))\n",
        "\n",
        "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif3 = snn.Leaky(beta=beta, learn_beta=True, threshold=0.9,\n",
        "                              spike_grad=surrogate.fast_sigmoid(slope=25))\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)  # Prevent overfitting\n",
        "\n",
        "        # Xavier Normal Initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_neurons, time_steps = x.shape\n",
        "        x = x.permute(2, 0, 1)  # (time, batch, neurons)\n",
        "\n",
        "        mem1, mem2, mem3 = [torch.zeros(batch_size, layer.out_features, device=x.device)\n",
        "                             for layer in [self.fc1, self.fc2, self.fc3]]\n",
        "        spk3_rec = []\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            spk1, mem1 = self.lif1(self.bn1(self.fc1(x[t])), mem1)\n",
        "            spk2, mem2 = self.lif2(self.bn2(self.fc2(spk1) + spk1), mem2)  # Residual Connection\n",
        "            spk2 = self.dropout(spk2)\n",
        "            spk3, mem3 = self.lif3(self.fc3(spk2), mem3)\n",
        "            spk3_rec.append(spk3)\n",
        "\n",
        "        spk3_rec = torch.stack(spk3_rec, dim=0).mean(0)  # Max-over-time readout\n",
        "        return spk3_rec\n",
        "\n",
        "# Instantiate Model\n",
        "model = SNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Data Loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(train_spike_trains, train_labels)), batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(test_spike_trains, test_labels)), batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    scheduler.step(avg_loss)  # Adjust learning rate dynamically\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Testing Loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Emht6KEh8x"
      },
      "source": [
        "## Spiking Heidelberg Digits (SHD) Data Set\n",
        "- Failing at reading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CflcZ73wEtpw",
        "outputId": "945344e3-dfef-4722-8464-cf686a52c3aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.12.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht1QW0gylv1W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import h5py\n",
        "import numpy as np\n",
        "import spikingjelly.activation_based as sj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4pdh8rTmGkB",
        "outputId": "ff7a5921-741f-4cc7-8b79-2c339165d129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded shd_train.h5.gz\n",
            "Decompressed to /content/shd_train.h5\n",
            "Removed /content/shd_train.h5.gz\n",
            "Downloaded shd_test.h5.gz\n",
            "Decompressed to /content/shd_test.h5\n",
            "Removed /content/shd_test.h5.gz\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "# Define the base URL and filenames\n",
        "base_url = \"https://zenkelab.org/datasets\"\n",
        "files = [\"shd_train.h5.gz\", \"shd_test.h5.gz\"]\n",
        "\n",
        "# Function to download and decompress the dataset\n",
        "def download_and_decompress(filename):\n",
        "    url = f\"{base_url}/{filename}\"\n",
        "    gz_file_path = os.path.join(\"/content\", filename)\n",
        "    hdf5_file_path = gz_file_path[:-3]\n",
        "\n",
        "    # Download the compressed dataset\n",
        "    urllib.request.urlretrieve(url, gz_file_path)\n",
        "    print(f\"Downloaded {filename}\")\n",
        "\n",
        "    # Decompress the dataset\n",
        "    with gzip.open(gz_file_path, 'rb') as f_in:\n",
        "        with open(hdf5_file_path, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "    print(f\"Decompressed to {hdf5_file_path}\")\n",
        "\n",
        "    # Remove the compressed file\n",
        "    os.remove(gz_file_path)\n",
        "    print(f\"Removed {gz_file_path}\")\n",
        "\n",
        "# Download and decompress each file\n",
        "for file in files:\n",
        "    download_and_decompress(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb-VcsaGmuu2",
        "outputId": "aaa0d735-bd22-4cc1-93ed-ada9ff6e3e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available keys in dataset: ['extra', 'labels', 'spikes']\n",
            "Available keys in dataset: ['extra', 'labels', 'spikes']\n"
          ]
        }
      ],
      "source": [
        "def inspect_hdf5(file_path):\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        print(\"Available keys in dataset:\", list(f.keys()))\n",
        "\n",
        "inspect_hdf5(\"/content/shd_train.h5\")\n",
        "inspect_hdf5(\"/content/shd_test.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkh5R_AblszJ",
        "outputId": "c02726a3-53e8-4022-9636-696c048810f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method MappingHDF5.keys of <HDF5 file \"shd_train.h5\" (mode r)>>\n",
            "<bound method MappingHDF5.keys of <HDF5 file \"shd_test.h5\" (mode r)>>\n"
          ]
        }
      ],
      "source": [
        "def load_shd_data(file_path):\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        print(f.keys)\n",
        "        return 1,1\n",
        "        # labels = f['labels'][]  # Class labels\n",
        "        # spikes = f['spikes'][]  # Spike times\n",
        "        # return spikes, labels\n",
        "\n",
        "# Download SHD dataset from SpikingJelly\n",
        "train_data, train_labels = load_shd_data(\"shd_train.h5\")\n",
        "test_data, test_labels = load_shd_data(\"shd_test.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1x5c4Ko1ExK4"
      },
      "outputs": [],
      "source": [
        "def convert_to_tensor(spike_data, labels, time_window=100):\n",
        "    num_samples = len(spike_data)\n",
        "    num_neurons = 700  # SHD input size\n",
        "    spike_tensor = torch.zeros((num_samples, num_neurons, time_window))\n",
        "\n",
        "    for i, spikes in enumerate(spike_data):\n",
        "        for neuron_id, spike_time in spikes:\n",
        "            if spike_time < time_window:\n",
        "                spike_tensor[i, neuron_id, int(spike_time)] = 1  # Set spike at correct time\n",
        "\n",
        "    return spike_tensor, torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Convert SHD data\n",
        "time_window = 100  # Simulation time steps\n",
        "train_spikes, train_labels = convert_to_tensor(train_data, train_labels, time_window)\n",
        "test_spikes, test_labels = convert_to_tensor(test_data, test_labels, time_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYt-BJXNoSzh"
      },
      "outputs": [],
      "source": [
        "class SNN(nn.Module):\n",
        "    def __init__(self, num_inputs=700, num_hidden=256, num_outputs=20):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = neuron.LIFNode(surrogate_function=surrogate.Sigmoid())\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = neuron.LIFNode(surrogate_function=surrogate.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_neurons, time_steps = x.shape\n",
        "        x = x.permute(2, 0, 1)  # (time, batch, neurons)\n",
        "        mem1 = torch.zeros(batch_size, 256, device=x.device)\n",
        "        mem2 = torch.zeros(batch_size, 20, device=x.device)\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            mem1 = self.lif1(self.fc1(x[t]))\n",
        "            mem2 = self.lif2(self.fc2(mem1))\n",
        "\n",
        "        return mem2  # Output as final membrane potential\n",
        "\n",
        "# Initialize Model\n",
        "model = SNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfYiJzyioULT"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "G_6YoSgdoV33",
        "outputId": "e4f7f4be-d3b5-464a-ac6d-f845c733e528"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_spikes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-38b304f7d44b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_loader = torch.utils.data.DataLoader(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_spikes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_spikes' is not defined"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(train_spikes, train_labels)), batch_size=batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(test_spikes, test_labels)), batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        functional.reset_net(model)  # Reset neuron states\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV2IwY-uoXuw"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        functional.reset_net(model)  # Reset states\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "M5xBtmPhE60p",
        "uqxoFyEr83Tb",
        "j9zVbkRR9WG1",
        "p2Emht6KEh8x"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMf/ketF7F7XyAmdOszCYcH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}