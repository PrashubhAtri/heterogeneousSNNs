{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttn7nN3Fnhhp",
        "outputId": "2f7defac-533f-4ff9-dd74-ec2f02e26bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tonic\n",
            "  Downloading tonic-1.6.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from tonic) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from tonic) (3.12.1)\n",
            "Collecting importRosbag>=1.0.4 (from tonic)\n",
            "  Downloading importRosbag-1.0.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tonic) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tonic) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from tonic) (4.12.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from tonic) (0.10.2.post1)\n",
            "Collecting pbr (from tonic)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting expelliarmus (from tonic)\n",
            "  Downloading expelliarmus-1.1.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa->tonic) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->tonic) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->tonic) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->tonic) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->tonic) (2.22)\n",
            "Downloading tonic-1.6.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importRosbag-1.0.4-py3-none-any.whl (28 kB)\n",
            "Downloading expelliarmus-1.1.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: snntorch, pbr, importRosbag, expelliarmus, tonic\n",
            "Successfully installed expelliarmus-1.1.12 importRosbag-1.0.4 pbr-6.1.1 snntorch-0.9.4 tonic-1.6.0\n",
            "Collecting weave\n",
            "  Downloading weave-0.51.43-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting diskcache==5.6.3 (from weave)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting emoji>=2.12.1 (from weave)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting gql[aiohttp,requests] (from weave)\n",
            "  Downloading gql-3.5.2-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: jsonschema>=4.23.0 in /usr/local/lib/python3.11/dist-packages (from weave) (4.23.0)\n",
            "Requirement already satisfied: numpy>1.21.0 in /usr/local/lib/python3.11/dist-packages (from weave) (1.26.4)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.11/dist-packages (from weave) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from weave) (2.10.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from weave) (13.9.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.11/dist-packages (from weave) (9.0.0)\n",
            "Collecting uuid-utils>=0.9.0 (from weave)\n",
            "  Downloading uuid_utils-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: wandb>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from weave) (0.19.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (0.23.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->weave) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->weave) (4.12.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (75.1.0)\n",
            "Collecting graphql-core<3.2.5,>=3.2 (from gql[aiohttp,requests]->weave)\n",
            "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (1.18.3)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[aiohttp,requests]->weave)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (3.7.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (3.11.13)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->weave) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->weave) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (0.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (1.3.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.17.1->weave) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->weave) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (5.0.2)\n",
            "Downloading weave-0.51.43-py3-none-any.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.7/473.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uuid_utils-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gql-3.5.2-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uuid-utils, graphql-core, emoji, diskcache, backoff, gql, weave\n",
            "Successfully installed backoff-2.2.1 diskcache-5.6.3 emoji-2.14.1 gql-3.5.2 graphql-core-3.2.4 uuid-utils-0.10.0 weave-0.51.43\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!pip install tonic wandb snntorch\n",
        "!pip install weave\n",
        "!wandb login ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AsZEDSF4ivOM",
        "outputId": "9b8308ef-e6b3-4667-9f48-0273f6541d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 48.05%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 45.31%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 47.27%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 47.66%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 53.91%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 54.30%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 51.56%\n",
            "Validation Accuracy: 0.5240 | std: 0.1000 | samples: 1000 | acc_thresh: 0.9000\n",
            "Epoch 1\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 51.17%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 46.88%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 49.61%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 49.22%\n",
            "    Batch Accuracy: 49.61%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 54.69%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 54.69%\n",
            "Validation Accuracy: 0.6490 | std: 0.0973 | samples: 973 | acc_thresh: 0.9024\n",
            "Epoch 2\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 74.61%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 87.11%\n",
            "Adaptive Pooling | Epoch 0\n",
            "    Batch Accuracy: 94.14%\n",
            "Adaptive Pooling | Epoch 1\n",
            "    Batch Accuracy: 95.70%\n",
            "Adaptive Pooling | Epoch 1\n",
            "    Batch Accuracy: 96.48%\n",
            "    Batch Accuracy: 91.02%\n",
            "    Batch Accuracy: 95.31%\n",
            "Validation Accuracy: 0.9591 | std: 0.0947 | samples: 946 | acc_thresh: 0.9047\n",
            "Epoch 3\n",
            "    Batch Accuracy: 94.14%\n",
            "Adaptive Pooling | Epoch 1\n",
            "    Batch Accuracy: 92.58%\n",
            "    Batch Accuracy: 93.36%\n",
            "    Batch Accuracy: 94.14%\n",
            "    Batch Accuracy: 96.09%\n",
            "    Batch Accuracy: 96.09%\n",
            "Adaptive Pooling | Epoch 1\n",
            "    Batch Accuracy: 96.88%\n",
            "Validation Accuracy: 0.9663 | std: 0.0921 | samples: 921 | acc_thresh: 0.9070\n",
            "Epoch 4\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 97.66%\n",
            "Adaptive Pooling | Epoch 1\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 100.00%\n",
            "Validation Accuracy: 0.9688 | std: 0.0897 | samples: 896 | acc_thresh: 0.9092\n",
            "Epoch 5\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 99.22%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 98.05%\n",
            "Adaptive Pooling | Epoch 1\n",
            "    Batch Accuracy: 96.88%\n",
            "Validation Accuracy: 0.9591 | std: 0.0873 | samples: 872 | acc_thresh: 0.9113\n",
            "Epoch 6\n",
            "Adaptive Pooling | Epoch 1\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.83%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 96.09%\n",
            "    Batch Accuracy: 96.88%\n",
            "Validation Accuracy: 0.9784 | std: 0.0850 | samples: 849 | acc_thresh: 0.9134\n",
            "Epoch 7\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 99.22%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 95.31%\n",
            "Validation Accuracy: 0.9808 | std: 0.0827 | samples: 827 | acc_thresh: 0.9154\n",
            "Epoch 8\n",
            "    Batch Accuracy: 95.31%\n",
            "    Batch Accuracy: 98.83%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.83%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 98.44%\n",
            "Validation Accuracy: 0.9808 | std: 0.0805 | samples: 805 | acc_thresh: 0.9173\n",
            "Epoch 9\n",
            "    Batch Accuracy: 99.22%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 98.44%\n",
            "Validation Accuracy: 0.9832 | std: 0.0784 | samples: 784 | acc_thresh: 0.9192\n",
            "Epoch 10\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 100.00%\n",
            "Validation Accuracy: 0.9736 | std: 0.0764 | samples: 763 | acc_thresh: 0.9210\n",
            "Epoch 11\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 98.83%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 100.00%\n",
            "Validation Accuracy: 0.9736 | std: 0.0744 | samples: 743 | acc_thresh: 0.9228\n",
            "Epoch 12\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.83%\n",
            "    Batch Accuracy: 98.44%\n",
            "Validation Accuracy: 0.9760 | std: 0.0724 | samples: 724 | acc_thresh: 0.9245\n",
            "Epoch 13\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 96.48%\n",
            "    Batch Accuracy: 100.00%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 96.88%\n",
            "Validation Accuracy: 0.9760 | std: 0.0706 | samples: 705 | acc_thresh: 0.9262\n",
            "Epoch 14\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 98.83%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 96.88%\n",
            "Validation Accuracy: 0.9712 | std: 0.0688 | samples: 687 | acc_thresh: 0.9278\n",
            "Epoch 15\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 98.44%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 96.88%\n",
            "Validation Accuracy: 0.9663 | std: 0.0670 | samples: 669 | acc_thresh: 0.9293\n",
            "Epoch 16\n",
            "Adaptive Pooling | Epoch 4\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 92.19%\n",
            "Validation Accuracy: 0.9567 | std: 0.0653 | samples: 652 | acc_thresh: 0.9309\n",
            "Epoch 17\n",
            "    Batch Accuracy: 96.48%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 96.48%\n",
            "    Batch Accuracy: 98.05%\n",
            "    Batch Accuracy: 97.66%\n",
            "    Batch Accuracy: 100.00%\n",
            "Validation Accuracy: 0.9567 | std: 0.0636 | samples: 636 | acc_thresh: 0.9323\n",
            "Epoch 18\n",
            "    Batch Accuracy: 98.83%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 96.09%\n",
            "    Batch Accuracy: 97.27%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 98.44%\n",
            "Validation Accuracy: 0.9639 | std: 0.0620 | samples: 620 | acc_thresh: 0.9338\n",
            "Epoch 19\n",
            "    Batch Accuracy: 96.09%\n",
            "    Batch Accuracy: 96.88%\n",
            "    Batch Accuracy: 98.83%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-45d3941a861e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0mtrain_snn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-45d3941a861e>\u001b[0m in \u001b[0;36mtrain_snn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 mean, velocity, personal_best, global_best = hybrid_update(\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelocity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersonal_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-45d3941a861e>\u001b[0m in \u001b[0;36mhybrid_update\u001b[0;34m(mean, velocity, personal_best, global_best, loss_fn, std, samples, x, y, lr, acc_threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-45d3941a861e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mcur1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mspk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mcur2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/snntorch/_neurons/leaky.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    218\u001b[0m             )  # batch_size\n\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mspk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_delay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/snntorch/_neurons/neurons.py\u001b[0m in \u001b[0;36mfire\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mmem_shift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mspk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspike_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mspk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraded_spikes_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/snntorch/surrogate.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mATan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/snntorch/surrogate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input_, alpha)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import snntorch as snn\n",
        "import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---- SNN Architecture with Sparse Connectivity ----\n",
        "class SNN(nn.Module):\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs, learn_beta=False, beta=0.95, sparsity=0.8):\n",
        "        super(SNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden, bias=False)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs, bias=False)\n",
        "        self.lif1 = snn.Leaky(beta=beta, learn_beta=learn_beta)\n",
        "        self.lif2 = snn.Leaky(beta=beta, learn_beta=learn_beta, reset_mechanism='none')\n",
        "\n",
        "        # Apply sparsity masks to fc1 and fc2\n",
        "        with torch.no_grad():\n",
        "            mask1 = torch.rand_like(self.fc1.weight) > sparsity\n",
        "            mask2 = torch.rand_like(self.fc2.weight) > sparsity\n",
        "            self.fc1.weight.data *= mask1\n",
        "            self.fc2.weight.data *= mask2\n",
        "            self.register_buffer(\"mask1\", mask1)\n",
        "            self.register_buffer(\"mask2\", mask2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem2_rec = []\n",
        "        for t in range(x.size(1)):\n",
        "            cur1 = self.fc1(x[:, t])\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            _, mem2 = self.lif2(cur2, mem2)\n",
        "            mem2_rec.append(mem2)\n",
        "        return torch.stack(mem2_rec, dim=1)  # (batch, time, outputs)\n",
        "\n",
        "# ---- Hybrid Parameter Update (PSO-inspired + adaptive Pool) ----\n",
        "def hybrid_update(mean, velocity, personal_best, global_best, loss_fn, std, samples, x, y, lr=0.1, acc_threshold=0.95):\n",
        "    sample_batch = mean + std * torch.randn(samples, *mean.shape).to(mean.device)\n",
        "    losses = []\n",
        "    accs = []\n",
        "\n",
        "    for i in range(samples):\n",
        "        model = SNN(*x.shape[2:], 10, 2).to(mean.device)\n",
        "        with torch.no_grad():\n",
        "            flat_params = sample_batch[i]\n",
        "            offset = 0\n",
        "            for p in model.parameters():\n",
        "                numel = p.numel()\n",
        "                p.data.copy_(flat_params[offset:offset+numel].view_as(p))\n",
        "                offset += numel\n",
        "            output = model(x)\n",
        "            loss = loss_fn(output.mean(1), y)\n",
        "            pred = output.mean(1).argmax(1)\n",
        "            acc = (pred == y).float().mean().item()\n",
        "            losses.append(loss.item())\n",
        "            accs.append(acc)\n",
        "\n",
        "    losses = torch.tensor(losses, device=mean.device)\n",
        "    accs = torch.tensor(accs, device=mean.device)\n",
        "\n",
        "    best_idx = torch.argmin(losses)\n",
        "    if losses[best_idx] < loss_fn(model(x).mean(1), y):\n",
        "        global_best = sample_batch[best_idx].clone()\n",
        "\n",
        "    # PSO update\n",
        "    r1, r2 = torch.rand(2)\n",
        "    velocity = 0.5 * velocity + 1.5 * r1 * (personal_best - mean) + 1.5 * r2 * (global_best - mean)\n",
        "    mean = mean + lr * velocity\n",
        "\n",
        "    # Adaptive Pooling\n",
        "    if accs[best_idx] < acc_threshold:\n",
        "        print(f\"Adaptive Pooling |\", end = ' ')\n",
        "        topk = sample_batch[torch.argsort(losses)[:samples//4]]\n",
        "        mean = topk.mean(dim=0)\n",
        "\n",
        "    # Log batch best performance (optional)\n",
        "    with torch.no_grad():\n",
        "        model = SNN(*x.shape[2:], 10, 2).to(mean.device)\n",
        "        offset = 0\n",
        "        for p in model.parameters():\n",
        "            numel = p.numel()\n",
        "            p.data.copy_(mean[offset:offset+numel].view_as(p))\n",
        "            offset += numel\n",
        "        output = model(x)\n",
        "        pred = output.mean(1).argmax(1)\n",
        "        acc = (pred == y).float().mean().item()\n",
        "        print(f\"    Batch Accuracy: {acc * 100:.2f}%\")\n",
        "        wandb.log({\"train_acc\": acc})\n",
        "\n",
        "    personal_best = mean.clone()\n",
        "    return mean, velocity, personal_best, global_best\n",
        "\n",
        "# ---- Annealing Schedulers ----\n",
        "def get_annealed_param(init, final, current_epoch, total_epochs, mode='exp'):\n",
        "    if mode == 'linear':\n",
        "        return final + (init - final) * (1 - current_epoch / total_epochs)\n",
        "    elif mode == 'exp':\n",
        "        return final + (init - final) * (0.97 ** current_epoch)\n",
        "    else:\n",
        "        return init\n",
        "\n",
        "# ---- Train Function ----\n",
        "def train_snn():\n",
        "    run_name = 'EA_2_classes_randman2'\n",
        "    config = {\n",
        "        'nb_input': 100, 'nb_output': 2, 'nb_steps': 50, 'nb_data_samples': 1000,\n",
        "        'nb_hidden': 10, 'learn_beta': False, 'nb_model_samples': 100,\n",
        "        'std': 0.05, 'epochs': 20, 'batch_size': 256,\n",
        "        'loss': 'cross-entropy', 'optimizer': 'Adam', 'lr': 0.01, 'regularization': 'none'\n",
        "    }\n",
        "\n",
        "    wandb.init(entity='DarwinNeuron', project='EA-Randman', name=run_name, config=config)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        dataset = get_randman_dataset(config['nb_output'], config['nb_input'], config['nb_steps'], config['nb_data_samples'])\n",
        "        train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, shuffle=False)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "        sample_model = SNN(config['nb_input'], config['nb_hidden'], config['nb_output'])\n",
        "        param_vector = torch.cat([p.flatten() for p in sample_model.parameters()]).detach()\n",
        "        mean = param_vector.clone()\n",
        "        velocity = torch.zeros_like(mean)\n",
        "        personal_best = mean.clone()\n",
        "        global_best = mean.clone()\n",
        "\n",
        "        for epoch in range(config['epochs']):\n",
        "            print(f\"Epoch {epoch}\")\n",
        "            current_std = get_annealed_param(init=0.1, final=0.01, current_epoch=epoch, total_epochs=config['epochs'])\n",
        "            current_samples = int(get_annealed_param(init=1000, final=100, current_epoch=epoch, total_epochs=config['epochs']))\n",
        "            acc_thresh = get_annealed_param(init=0.90, final=0.98, current_epoch=epoch, total_epochs=config['epochs'])\n",
        "\n",
        "            for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "                x_batch, y_batch = x_batch.float(), y_batch.long()\n",
        "                mean, velocity, personal_best, global_best = hybrid_update(\n",
        "                    mean, velocity, personal_best, global_best,\n",
        "                    nn.CrossEntropyLoss(), current_std, current_samples,\n",
        "                    x_batch, y_batch, lr=config['lr'], acc_threshold=acc_thresh\n",
        "                )\n",
        "\n",
        "            # ---- Evaluate validation set ----\n",
        "            val_accs = []\n",
        "            with torch.no_grad():\n",
        "                model = SNN(config['nb_input'], config['nb_hidden'], config['nb_output']).to(mean.device)\n",
        "                offset = 0\n",
        "                for p in model.parameters():\n",
        "                    numel = p.numel()\n",
        "                    p.data.copy_(mean[offset:offset+numel].view_as(p))\n",
        "                    offset += numel\n",
        "\n",
        "                for x_val, y_val in val_loader:\n",
        "                    x_val, y_val = x_val.float().to(mean.device), y_val.long().to(mean.device)\n",
        "                    output = model(x_val)\n",
        "                    pred = output.mean(1).argmax(1)\n",
        "                    acc = (pred == y_val).float().mean().item()\n",
        "                    val_accs.append(acc)\n",
        "\n",
        "                val_accuracy = sum(val_accs) / len(val_accs)\n",
        "                print(f\"Validation Accuracy: {val_accuracy:.4f} | std: {current_std:.4f} | samples: {current_samples} | acc_thresh: {acc_thresh:.4f}\")\n",
        "                wandb.log({\n",
        "                    \"val_accuracy\": val_accuracy,\n",
        "                    \"epoch\": epoch,\n",
        "                    \"std\": current_std,\n",
        "                    \"samples\": current_samples,\n",
        "                    \"acc_threshold\": acc_thresh\n",
        "                })\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "train_snn()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
