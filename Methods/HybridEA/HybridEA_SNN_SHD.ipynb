{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttn7nN3Fnhhp",
    "outputId": "2f7defac-533f-4ff9-dd74-ec2f02e26bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tonic\n",
      "  Using cached tonic-1.6.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: wandb in /home/wx2178/.local/lib/python3.12/site-packages (0.19.9)\n",
      "Collecting snntorch\n",
      "  Using cached snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in /ext3/miniconda3/lib/python3.12/site-packages (from tonic) (1.26.4)\n",
      "Collecting h5py (from tonic)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting importRosbag>=1.0.4 (from tonic)\n",
      "  Using cached importRosbag-1.0.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: scipy in /ext3/miniconda3/lib/python3.12/site-packages (from tonic) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /ext3/miniconda3/lib/python3.12/site-packages (from tonic) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in /ext3/miniconda3/lib/python3.12/site-packages (from tonic) (4.12.1)\n",
      "Collecting librosa (from tonic)\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting pbr (from tonic)\n",
      "  Using cached pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting expelliarmus (from tonic)\n",
      "  Downloading expelliarmus-1.1.12.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /ext3/miniconda3/lib/python3.12/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /ext3/miniconda3/lib/python3.12/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3 in /ext3/miniconda3/lib/python3.12/site-packages (from wandb) (2.7.2)\n",
      "Requirement already satisfied: pyyaml in /ext3/miniconda3/lib/python3.12/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /ext3/miniconda3/lib/python3.12/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /home/wx2178/.local/lib/python3.12/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /ext3/miniconda3/lib/python3.12/site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /ext3/miniconda3/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/wx2178/.local/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /ext3/miniconda3/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /ext3/miniconda3/lib/python3.12/site-packages (from pydantic<3->wandb) (2.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ext3/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ext3/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Collecting audioread>=2.1.9 (from librosa->tonic)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->tonic)\n",
      "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /ext3/miniconda3/lib/python3.12/site-packages (from librosa->tonic) (1.5.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /ext3/miniconda3/lib/python3.12/site-packages (from librosa->tonic) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /ext3/miniconda3/lib/python3.12/site-packages (from librosa->tonic) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa->tonic)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa->tonic)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->tonic)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /ext3/miniconda3/lib/python3.12/site-packages (from librosa->tonic) (0.4)\n",
      "Collecting msgpack>=1.0 (from librosa->tonic)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/wx2178/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: packaging in /ext3/miniconda3/lib/python3.12/site-packages (from lazy_loader>=0.1->librosa->tonic) (23.2)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa->tonic)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa->tonic) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /ext3/miniconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa->tonic) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /ext3/miniconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->tonic) (2.21)\n",
      "Using cached tonic-1.6.0-py3-none-any.whl (106 kB)\n",
      "Using cached snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
      "Using cached importRosbag-1.0.4-py3-none-any.whl (28 kB)\n",
      "Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.4/401.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.5/248.5 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: expelliarmus\n",
      "  Building wheel for expelliarmus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for expelliarmus: filename=expelliarmus-1.1.12-cp312-cp312-linux_x86_64.whl size=28265 sha256=d1eb33fa944c62ff0888aeafce71e110cfee103d85fd1185438c52179853c88f\n",
      "  Stored in directory: /home/wx2178/.cache/pip/wheels/9a/9e/4b/f96da4dab397e63f90078766122e078e4ba82b2b48e07ee644\n",
      "Successfully built expelliarmus\n",
      "Installing collected packages: soxr, snntorch, pbr, msgpack, llvmlite, importRosbag, h5py, expelliarmus, audioread, soundfile, pooch, numba, librosa, tonic\n",
      "\u001b[33m  WARNING: The script pbr is installed in '/home/wx2178/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed audioread-3.0.1 expelliarmus-1.1.12 h5py-3.13.0 importRosbag-1.0.4 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.2 pbr-6.1.1 pooch-1.8.2 snntorch-0.9.4 soundfile-0.13.1 soxr-0.5.0.post1 tonic-1.6.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting weave\n",
      "  Downloading weave-0.51.43-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting diskcache==5.6.3 (from weave)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting emoji>=2.12.1 (from weave)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting gql[aiohttp,requests] (from weave)\n",
      "  Using cached gql-3.5.2-py2.py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting jsonschema>=4.23.0 (from weave)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy>1.21.0 in /ext3/miniconda3/lib/python3.12/site-packages (from weave) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.0 in /ext3/miniconda3/lib/python3.12/site-packages (from weave) (23.2)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /ext3/miniconda3/lib/python3.12/site-packages (from weave) (2.7.2)\n",
      "Collecting rich (from weave)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity!=8.4.0,>=8.3.0 (from weave)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting uuid-utils>=0.9.0 (from weave)\n",
      "  Using cached uuid_utils-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: wandb>=0.17.1 in /home/wx2178/.local/lib/python3.12/site-packages (from weave) (0.19.9)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.23.0->weave) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /ext3/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.23.0->weave) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /ext3/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.23.0->weave) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /ext3/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.23.0->weave) (0.18.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /ext3/miniconda3/lib/python3.12/site-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /ext3/miniconda3/lib/python3.12/site-packages (from pydantic>=2.0.0->weave) (2.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /ext3/miniconda3/lib/python3.12/site-packages (from pydantic>=2.0.0->weave) (4.12.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /ext3/miniconda3/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /ext3/miniconda3/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /ext3/miniconda3/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /ext3/miniconda3/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/wx2178/.local/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /home/wx2178/.local/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /ext3/miniconda3/lib/python3.12/site-packages (from wandb>=0.17.1->weave) (69.5.1)\n",
      "Collecting graphql-core<3.2.5,>=3.2 (from gql[aiohttp,requests]->weave)\n",
      "  Using cached graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.6 (from gql[aiohttp,requests]->weave)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting backoff<3.0,>=1.11.1 (from gql[aiohttp,requests]->weave)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.0 in /ext3/miniconda3/lib/python3.12/site-packages (from gql[aiohttp,requests]->weave) (4.4.0)\n",
      "Collecting aiohttp<4,>=3.9.0b0 (from gql[aiohttp,requests]->weave)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting requests-toolbelt<2,>=1.0.0 (from gql[aiohttp,requests]->weave)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->weave)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /ext3/miniconda3/lib/python3.12/site-packages (from rich->weave) (2.15.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4,>=3.9.0b0->gql[aiohttp,requests]->weave)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4,>=3.9.0b0->gql[aiohttp,requests]->weave)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.9.0b0->gql[aiohttp,requests]->weave)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.9.0b0->gql[aiohttp,requests]->weave)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.9.0b0->gql[aiohttp,requests]->weave)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /ext3/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /ext3/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (1.3.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /ext3/miniconda3/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb>=0.17.1->weave) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/wx2178/.local/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (4.0.12)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->weave)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ext3/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ext3/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/wx2178/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (5.0.2)\n",
      "Downloading weave-0.51.43-py3-none-any.whl (473 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.7/473.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached uuid_utils-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.2/349.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached gql-3.5.2-py2.py3-none-any.whl (74 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m321.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.5/223.5 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uuid-utils, tenacity, propcache, multidict, mdurl, graphql-core, frozenlist, emoji, diskcache, backoff, aiohappyeyeballs, yarl, requests-toolbelt, markdown-it-py, aiosignal, rich, jsonschema, gql, aiohttp, weave\n",
      "\u001b[33m  WARNING: The script markdown-it is installed in '/home/wx2178/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jsonschema is installed in '/home/wx2178/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script gql-cli is installed in '/home/wx2178/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 backoff-2.2.1 diskcache-5.6.3 emoji-2.14.1 frozenlist-1.6.0 gql-3.5.2 graphql-core-3.2.4 jsonschema-4.23.0 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.4.3 propcache-0.3.1 requests-toolbelt-1.0.0 rich-14.0.0 tenacity-9.1.2 uuid-utils-0.10.0 weave-0.51.43 yarl-1.20.0\n",
      "/bin/bash: line 1: wandb: command not found\n"
     ]
    }
   ],
   "source": [
    "# !pip install tonic wandb snntorch\n",
    "# !pip install weave\n",
    "# !wandb login ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-59528524/ipykernel_247409/72171792.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(torch.stack(spike_trains), dtype=torch.float32)  # [sample, time_step, unit]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import snntorch as snn\n",
    "import wandb\n",
    "import tonic\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load SHD\n",
    "def convert_to_tensor(spike_times, spike_units, num_neurons=700, time_bins=100):\n",
    "\n",
    "    spike_tensor = np.zeros((time_bins, num_neurons), dtype=np.float32)\n",
    "\n",
    "    # Normalize time into the `time_bins`\n",
    "    if len(spike_times) > 0:\n",
    "        time_idx = (spike_times / np.max(spike_times) * (time_bins - 1)).astype(int)\n",
    "        spike_tensor[time_idx, spike_units] = 1  # Mark neuron firing\n",
    "\n",
    "    return torch.tensor(spike_tensor, dtype=torch.float32)\n",
    "\n",
    "def get_SHD_dataset(SHD_raw, num_neurons=700, time_bins=100):\n",
    "    spike_trains = []\n",
    "    labels = []\n",
    "    for i, (events, label) in enumerate(SHD_raw):\n",
    "        # events has shape (nb_spikes,), each entry is array([t(spike time), x(unit), p])\n",
    "        spike_times = events['t']\n",
    "        spike_units = events['x']\n",
    "        spike_trains.append(convert_to_tensor(spike_times, spike_units))\n",
    "        labels.append(label)\n",
    "    X = torch.tensor(torch.stack(spike_trains), dtype=torch.float32)  # [sample, time_step, unit]\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "SHD_train_raw = tonic.datasets.SHD(save_to='../tonic_data', train=True)\n",
    "SHD_test_raw = tonic.datasets.SHD(save_to='../tonic_data', train=False)\n",
    "\n",
    "train_dataset = get_SHD_dataset(SHD_train_raw)\n",
    "test_dataset = get_SHD_dataset(SHD_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AsZEDSF4ivOM",
    "outputId": "9b8308ef-e6b3-4667-9f48-0273f6541d8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">EA_hybrid_SHD</strong> at: <a href='https://wandb.ai/DarwinNeuron/EA-Randman/runs/zegf7lxb' target=\"_blank\">https://wandb.ai/DarwinNeuron/EA-Randman/runs/zegf7lxb</a><br> View project at: <a href='https://wandb.ai/DarwinNeuron/EA-Randman' target=\"_blank\">https://wandb.ai/DarwinNeuron/EA-Randman</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_071808-zegf7lxb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/wx2178/others/wandb/run-20250421_071843-veylbibq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/DarwinNeuron/EA-SHD/runs/veylbibq' target=\"_blank\">EA_hybrid_SHD</a></strong> to <a href='https://wandb.ai/DarwinNeuron/EA-SHD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/DarwinNeuron/EA-SHD' target=\"_blank\">https://wandb.ai/DarwinNeuron/EA-SHD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/DarwinNeuron/EA-SHD/runs/veylbibq' target=\"_blank\">https://wandb.ai/DarwinNeuron/EA-SHD/runs/veylbibq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.52%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 7.42%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 6.25%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.30%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 2.73%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.47%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.52%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.08%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.69%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.08%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.30%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 2.73%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 6.64%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.08%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 6.64%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.47%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.47%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.30%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 2.73%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 2.73%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.08%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.30%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.69%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.52%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 6.25%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.69%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.91%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 8.20%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 7.42%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.08%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.47%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.45%\n",
      "Validation Accuracy: 0.0470 | std: 0.1000 | samples: 1000 | acc_thresh: 0.9000\n",
      "Epoch 1\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.30%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.91%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 7.81%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.69%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.91%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 6.64%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.91%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.52%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.91%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.30%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.30%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 3.52%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 4.69%\n",
      "Adaptive Pooling | Epoch 0\n",
      "    Batch Accuracy: 5.08%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- SNN Architecture with Sparse Connectivity ----\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, learn_beta=False, beta=0.95, sparsity=0.8):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden, bias=False)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs, bias=False)\n",
    "        self.lif1 = snn.Leaky(beta=beta, learn_beta=learn_beta)\n",
    "        self.lif2 = snn.Leaky(beta=beta, learn_beta=learn_beta, reset_mechanism='none')\n",
    "\n",
    "        # Apply sparsity masks to fc1 and fc2\n",
    "        with torch.no_grad():\n",
    "            mask1 = torch.rand_like(self.fc1.weight) > sparsity\n",
    "            mask2 = torch.rand_like(self.fc2.weight) > sparsity\n",
    "            self.fc1.weight.data *= mask1\n",
    "            self.fc2.weight.data *= mask2\n",
    "            self.register_buffer(\"mask1\", mask1)\n",
    "            self.register_buffer(\"mask2\", mask2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem2_rec = []\n",
    "        for t in range(x.size(1)):\n",
    "            cur1 = self.fc1(x[:, t])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            _, mem2 = self.lif2(cur2, mem2)\n",
    "            mem2_rec.append(mem2)\n",
    "        return torch.stack(mem2_rec, dim=1)  # (batch, time, outputs)\n",
    "\n",
    "# ---- Hybrid Parameter Update (PSO-inspired + adaptive Pool) ----\n",
    "def hybrid_update(mean, velocity, personal_best, global_best, loss_fn, std, samples, x, y, lr=0.1, acc_threshold=0.95):\n",
    "    sample_batch = mean + std * torch.randn(samples, *mean.shape).to(mean.device)\n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    for i in range(samples):\n",
    "        model = SNN(*x.shape[2:], 100, 20).to(mean.device) # input, hidden=100, output=20\n",
    "        with torch.no_grad():\n",
    "            flat_params = sample_batch[i]\n",
    "            offset = 0\n",
    "            for p in model.parameters():\n",
    "                numel = p.numel()\n",
    "                p.data.copy_(flat_params[offset:offset+numel].view_as(p))\n",
    "                offset += numel\n",
    "            output = model(x)\n",
    "            loss = loss_fn(output.mean(1), y)\n",
    "            pred = output.mean(1).argmax(1)\n",
    "            acc = (pred == y).float().mean().item()\n",
    "            losses.append(loss.item())\n",
    "            accs.append(acc)\n",
    "\n",
    "    losses = torch.tensor(losses, device=mean.device)\n",
    "    accs = torch.tensor(accs, device=mean.device)\n",
    "\n",
    "    best_idx = torch.argmin(losses)\n",
    "    if losses[best_idx] < loss_fn(model(x).mean(1), y):\n",
    "        global_best = sample_batch[best_idx].clone()\n",
    "\n",
    "    # PSO update\n",
    "    r1, r2 = torch.rand(2)\n",
    "    velocity = 0.5 * velocity + 1.5 * r1 * (personal_best - mean) + 1.5 * r2 * (global_best - mean)\n",
    "    mean = mean + lr * velocity\n",
    "\n",
    "    # Adaptive Pooling\n",
    "    if accs[best_idx] < acc_threshold:\n",
    "        print(f\"Adaptive Pooling |\", end = ' ')\n",
    "        topk = sample_batch[torch.argsort(losses)[:samples//4]]\n",
    "        mean = topk.mean(dim=0)\n",
    "\n",
    "    # Log batch best performance (optional)\n",
    "    with torch.no_grad():\n",
    "        model = SNN(*x.shape[2:], 10, 2).to(mean.device)\n",
    "        offset = 0\n",
    "        for p in model.parameters():\n",
    "            numel = p.numel()\n",
    "            p.data.copy_(mean[offset:offset+numel].view_as(p))\n",
    "            offset += numel\n",
    "        output = model(x)\n",
    "        pred = output.mean(1).argmax(1)\n",
    "        acc = (pred == y).float().mean().item()\n",
    "        print(f\"    Batch Accuracy: {acc * 100:.2f}%\")\n",
    "        wandb.log({\"train_acc\": acc})\n",
    "\n",
    "    personal_best = mean.clone()\n",
    "    return mean, velocity, personal_best, global_best\n",
    "\n",
    "# ---- Annealing Schedulers ----\n",
    "def get_annealed_param(init, final, current_epoch, total_epochs, mode='exp'):\n",
    "    if mode == 'linear':\n",
    "        return final + (init - final) * (1 - current_epoch / total_epochs)\n",
    "    elif mode == 'exp':\n",
    "        return final + (init - final) * (0.97 ** current_epoch)\n",
    "    else:\n",
    "        return init\n",
    "\n",
    "# ---- Train Function ----\n",
    "def train_snn():\n",
    "    run_name = 'EA_hybrid_SHD'\n",
    "    config = {\n",
    "        'nb_input': 700, 'nb_output': 20, 'nb_steps': 100, 'nb_data_samples': 8155,\n",
    "        'nb_hidden': 100, 'learn_beta': False, 'nb_model_samples': 1000,\n",
    "        'std': 0.05, 'epochs': 50, 'batch_size': 256,\n",
    "        'loss': 'cross-entropy', 'optimizer': 'Adam', 'lr': 0.01, 'regularization': 'none'\n",
    "    }\n",
    "\n",
    "    wandb.init(entity='DarwinNeuron', project='EA-SHD', name=run_name, config=config)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "        sample_model = SNN(config['nb_input'], config['nb_hidden'], config['nb_output'])\n",
    "        param_vector = torch.cat([p.flatten() for p in sample_model.parameters()]).detach()\n",
    "        mean = param_vector.clone()\n",
    "        velocity = torch.zeros_like(mean)\n",
    "        personal_best = mean.clone()\n",
    "        global_best = mean.clone()\n",
    "\n",
    "        for epoch in range(config['epochs']):\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            current_std = get_annealed_param(init=0.1, final=0.01, current_epoch=epoch, total_epochs=config['epochs'])\n",
    "            current_samples = int(get_annealed_param(init=1000, final=100, current_epoch=epoch, total_epochs=config['epochs']))\n",
    "            acc_thresh = get_annealed_param(init=0.90, final=0.98, current_epoch=epoch, total_epochs=config['epochs'])\n",
    "\n",
    "            for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "                x_batch, y_batch = x_batch.float(), y_batch.long()\n",
    "                mean, velocity, personal_best, global_best = hybrid_update(\n",
    "                    mean, velocity, personal_best, global_best,\n",
    "                    nn.CrossEntropyLoss(), current_std, current_samples,\n",
    "                    x_batch, y_batch, lr=config['lr'], acc_threshold=acc_thresh\n",
    "                )\n",
    "\n",
    "            # ---- Evaluate validation set ----\n",
    "            val_accs = []\n",
    "            with torch.no_grad():\n",
    "                model = SNN(config['nb_input'], config['nb_hidden'], config['nb_output']).to(mean.device)\n",
    "                offset = 0\n",
    "                for p in model.parameters():\n",
    "                    numel = p.numel()\n",
    "                    p.data.copy_(mean[offset:offset+numel].view_as(p))\n",
    "                    offset += numel\n",
    "\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val, y_val = x_val.float().to(mean.device), y_val.long().to(mean.device)\n",
    "                    output = model(x_val)\n",
    "                    pred = output.mean(1).argmax(1)\n",
    "                    acc = (pred == y_val).float().mean().item()\n",
    "                    val_accs.append(acc)\n",
    "\n",
    "                val_accuracy = sum(val_accs) / len(val_accs)\n",
    "                print(f\"Validation Accuracy: {val_accuracy:.4f} | std: {current_std:.4f} | samples: {current_samples} | acc_thresh: {acc_thresh:.4f}\")\n",
    "                wandb.log({\n",
    "                    \"val_accuracy\": val_accuracy,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"std\": current_std,\n",
    "                    \"samples\": current_samples,\n",
    "                    \"acc_threshold\": acc_thresh\n",
    "                })\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "train_snn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (resemble_denoise)",
   "language": "python",
   "name": "resemble_denoise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
